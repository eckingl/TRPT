import pandas as pd
import numpy as np
from datetime import datetime
import chardet
import tkinter as tk
from tkinter import filedialog, messagebox
from pypinyin import lazy_pinyin  # å¯¼å…¥æ‹¼éŸ³åº“
import openpyxl
import openpyxl.styles


# ========== å·¥å…·å‡½æ•° ==========
def get_pinyin_first_letter(text):
    """è·å–æ–‡æœ¬çš„æ‹¼éŸ³é¦–å­—æ¯ï¼ˆç”¨äºæ’åºï¼‰"""
    pinyin_list = lazy_pinyin(str(text))
    return ''.join(pinyin_list).lower()


def read_csv_safe(filepath):
    with open(filepath, 'rb') as f:
        raw = f.read(10000)
        enc = chardet.detect(raw)['encoding']
        if enc is None:
            enc = 'utf-8'
        if enc.lower() in ['gb2312', 'gbk', 'cp936']:
            enc = 'gbk'
    return pd.read_csv(filepath, encoding=enc)


def find_trzd_column(df):
    for col in df.columns:
        if col.strip().lower() == 'trzd':
            return col
    raise ValueError("æœªæ‰¾åˆ°åä¸º 'TRZD' çš„åˆ—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰")


# ========== TRZD æ˜ å°„é…ç½®ï¼ˆæ”¯æŒä¸­æ–‡è¾“å…¥ï¼‰==========
TRZD_NAME_TO_INFO = {
    "ç ‚åœŸåŠå£¤è´¨ç ‚åœŸ": ("ç ‚åœŸç±»", "ç ‚åœŸåŠå£¤è´¨ç ‚åœŸ", 1),
    "ç ‚è´¨å£¤åœŸ": ("ç ‚å£¤ç±»", "ç ‚è´¨å£¤åœŸ", 2),
    "ç²‰(ç ‚)è´¨å£¤åœŸ": ("è½»å£¤ç±»", "ç²‰(ç ‚)è´¨å£¤åœŸ", 3),
    "å£¤åœŸ": ("ä¸­å£¤ç±»", "å£¤åœŸ", 4),
    "ç ‚è´¨é»å£¤åœŸ": ("é»å£¤ç±»", "ç ‚è´¨é»å£¤åœŸ", 5),
    "é»å£¤åœŸ": ("é»å£¤ç±»", "é»å£¤åœŸ", 5),
    "ç²‰(ç ‚)è´¨é»å£¤åœŸ": ("é»å£¤ç±»", "ç²‰(ç ‚)è´¨é»å£¤åœŸ", 5),
    "ç ‚è´¨é»åœŸ": ("è½»é»ç±»", "ç ‚è´¨é»åœŸ", 6),
    "å£¤è´¨é»åœŸ": ("è½»é»ç±»", "å£¤è´¨é»åœŸ", 6),
    "ç²‰(ç ‚)è´¨é»åœŸ": ("è½»é»ç±»", "ç²‰(ç ‚)è´¨é»åœŸ", 6),
    "é»åœŸ": ("é»åœŸç±»", "é»åœŸ", 7),
    "é‡é»åœŸ": ("é»åœŸç±»", "é‡é»åœŸ", 7),
}

# åŠ¨æ€ç”Ÿæˆ GRADE_GROUPSï¼Œé¿å…å†—ä½™
from collections import defaultdict
GRADE_GROUPS = defaultdict(list)
for name, (_, _, grade) in TRZD_NAME_TO_INFO.items():
    if grade in [5, 6, 7]:
        GRADE_GROUPS[grade].append(name)
GRADE_GROUPS = dict(GRADE_GROUPS)

# å®šä¹‰è´¨åœ°ç»“æ„ï¼Œç”¨äºæ„å»ºåˆ—ï¼ˆç§»é™¤åˆè®¡åˆ—ï¼‰
TEXTURE_STRUCTURE = [
    ["ç ‚åœŸåŠå£¤è´¨ç ‚åœŸ", "ç ‚è´¨å£¤åœŸ", "ç²‰(ç ‚)è´¨å£¤åœŸ", "å£¤åœŸ"],
    ["ç ‚è´¨é»å£¤åœŸ", "é»å£¤åœŸ", "ç²‰(ç ‚)è´¨é»å£¤åœŸ"],
    ["ç ‚è´¨é»åœŸ", "å£¤è´¨é»åœŸ", "ç²‰(ç ‚)è´¨é»åœŸ"],
    ["é»åœŸ", "é‡é»åœŸ"]
]

# é‡å»º TEXTURE_COLSï¼ˆæ‰€æœ‰è´¨åœ°ç±»å‹ï¼Œä¸åŒ…å«åˆè®¡åˆ—ï¼‰
TEXTURE_COLS = (
    TEXTURE_STRUCTURE[0] +
    TEXTURE_STRUCTURE[1] +
    TEXTURE_STRUCTURE[2] +
    TEXTURE_STRUCTURE[3]
)


def map_trzd_to_info(trzd_val):
    """å°† TRZD å€¼æ˜ å°„ä¸º (ç±»åˆ«, åç§°, åˆ†çº§)ï¼Œæ— æ•ˆå€¼è¿”å› (None, None, None)"""
    if pd.isna(trzd_val):
        return None, None, None
    trzd_str = str(trzd_val).strip()
    if trzd_str in ["0", "/", ""]:
        return None, None, None
    if trzd_str in TRZD_NAME_TO_INFO:
        return TRZD_NAME_TO_INFO[trzd_str]
    else:
        return "å…¶ä»–", f"æœªçŸ¥({trzd_str})", 99


# ========== è¡¨å¤´å®šä¹‰ ==========
# è¡¨2è¡¨å¤´ï¼ˆåœŸåœ°åˆ©ç”¨ç±»å‹ï¼‰
HEADER_TOP_2 = (
    ["åœŸåœ°åˆ©ç”¨ç±»å‹"] * 2 + ["é¢ç§¯/äº©", "æ ·ç‚¹/ä¸ª"] +
    ["æ ·ç‚¹ç»Ÿè®¡%"] * len(TEXTURE_COLS) + ["åˆ¶å›¾ç»Ÿè®¡%"] * len(TEXTURE_COLS)
)
HEADER_BOT_2 = (
    ["ä¸€çº§", "äºŒçº§", "é¢ç§¯/äº©", "æ ·ç‚¹/ä¸ª"] + TEXTURE_COLS + TEXTURE_COLS
)

# è¡¨3è¡¨å¤´ï¼ˆåœŸå£¤ç±»å‹ï¼‰
HEADER_TOP_3 = (
    ["åœŸå£¤ç±»å‹"] * 2 + ["é¢ç§¯/äº©", "æ ·ç‚¹/ä¸ª"] +
    ["æ ·ç‚¹ç»Ÿè®¡%"] * len(TEXTURE_COLS) + ["åˆ¶å›¾ç»Ÿè®¡%"] * len(TEXTURE_COLS)
)
HEADER_BOT_3 = (
    ["äºšç±»", "åœŸå±", "é¢ç§¯/äº©", "æ ·ç‚¹/ä¸ª"] + TEXTURE_COLS + TEXTURE_COLS
)

HEADER_TOP_4 = (
    ["ä¹¡é•‡", "é¢ç§¯/äº©", "æ ·ç‚¹/ä¸ª"] +
    ["æ ·ç‚¹ç»Ÿè®¡%"] * len(TEXTURE_COLS) + ["åˆ¶å›¾ç»Ÿè®¡%"] * len(TEXTURE_COLS)
)
HEADER_BOT_4 = (
    ["ä¹¡é•‡", "é¢ç§¯/äº©", "æ ·ç‚¹/ä¸ª"] + TEXTURE_COLS + TEXTURE_COLS
)


# ========== æ„å»ºè´¨åœ°è¡Œæ•°æ®ï¼ˆç§»é™¤åˆè®¡åˆ—ç‰ˆæœ¬ï¼‰==========
def build_texture_row(sample_df, area_df, total_sample_count, total_area_sum):
    texture_names = TEXTURE_COLS  # å·²ç»ä¸åŒ…å«"åˆè®¡"äº†

    # åˆå§‹åŒ–å­—å…¸
    texture_counts = {name: 0 for name in texture_names}
    texture_areas = {name: 0.0 for name in texture_names}

    if not sample_df.empty:
        counts_series = sample_df['è´¨åœ°åç§°'].value_counts()
        for name in texture_names:
            texture_counts[name] = counts_series.get(name, 0)

    if not area_df.empty:
        area_grouped = area_df.groupby('è´¨åœ°åç§°')['é¢ç§¯'].sum()
        for name in texture_names:
            texture_areas[name] = area_grouped.get(name, 0.0)

    sample_pcts = {}
    area_pcts = {}
    for name in texture_names:
        sample_pcts[name] = round(texture_counts[name] / total_sample_count * 100, 3) if total_sample_count > 0 else 0.0
        area_pcts[name] = round(texture_areas[name] / total_area_sum * 100, 3) if total_area_sum > 0 else 0.0

    # æŒ‰é¡ºåºæ„å»ºåˆ—è¡¨ï¼ˆä¸å†æ·»åŠ åˆè®¡åˆ—ï¼‰
    sample_pct_list = []
    area_pct_list = []

    for name in TEXTURE_COLS:
        sample_pct_list.append(sample_pcts.get(name, 0.0))
        area_pct_list.append(area_pcts.get(name, 0.0))

    return sample_pct_list + area_pct_list


# ========== ä¸»å¤„ç†å‡½æ•° ==========
def process_trzd_files(sample_path, area_paths, output_path):
    try:
        # è¯»å–æ ·ç‚¹æ–‡ä»¶ï¼ˆå•ä¸ªï¼‰
        df_sample = read_csv_safe(sample_path)

        # è¯»å–å¹¶åˆå¹¶å¤šä¸ªåˆ¶å›¾æ–‡ä»¶
        df_area_list = []
        for path in area_paths:
            df_temp = read_csv_safe(path)
            df_area_list.append(df_temp)
        df_area = pd.concat(df_area_list, ignore_index=True)

        trzd_col_s = find_trzd_column(df_sample)
        trzd_col_a = find_trzd_column(df_area)

        df_sample = df_sample.rename(columns={trzd_col_s: 'TRZD'})
        df_area = df_area.rename(columns={trzd_col_a: 'TRZD'})

        # æ£€æµ‹å¹¶ç»Ÿä¸€åˆ—åï¼ˆæ”¯æŒDLMCå’ŒäºŒçº§åœ°ç±»ï¼‰
        if 'äºŒçº§åœ°ç±»' in df_sample.columns:
            pass  # å·²ç»æ˜¯äºŒçº§åœ°ç±»
        elif 'DLMC' in df_sample.columns:
            df_sample = df_sample.rename(columns={'DLMC': 'äºŒçº§åœ°ç±»'})
        else:
            raise ValueError("æ ·ç‚¹æ–‡ä»¶ç¼ºå°‘'äºŒçº§åœ°ç±»'æˆ–'DLMC'åˆ—")
        
        if 'äºŒçº§åœ°ç±»' in df_area.columns:
            pass  # å·²ç»æ˜¯äºŒçº§åœ°ç±»
        elif 'DLMC' in df_area.columns:
            df_area = df_area.rename(columns={'DLMC': 'äºŒçº§åœ°ç±»'})
        else:
            raise ValueError("åˆ¶å›¾æ–‡ä»¶ç¼ºå°‘'äºŒçº§åœ°ç±»'æˆ–'DLMC'åˆ—")
        
        # æ£€æµ‹å¹¶ç»Ÿä¸€YLå’ŒTSåˆ—åï¼ˆæ”¯æŒSSub_JZg/YLå’ŒSGen_JZg/TSï¼‰
        if 'YL' in df_sample.columns:
            pass
        elif 'SSub_JZg' in df_sample.columns:
            df_sample = df_sample.rename(columns={'SSub_JZg': 'YL'})
        else:
            raise ValueError("æ ·ç‚¹æ–‡ä»¶ç¼ºå°‘'YL'æˆ–'SSub_JZg'åˆ—")
        
        if 'TS' in df_sample.columns:
            pass
        elif 'SGen_JZg' in df_sample.columns:
            df_sample = df_sample.rename(columns={'SGen_JZg': 'TS'})
        else:
            raise ValueError("æ ·ç‚¹æ–‡ä»¶ç¼ºå°‘'TS'æˆ–'SGen_JZg'åˆ—")
        
        if 'YL' in df_area.columns:
            pass
        elif 'SSub_JZg' in df_area.columns:
            df_area = df_area.rename(columns={'SSub_JZg': 'YL'})
        else:
            raise ValueError("åˆ¶å›¾æ–‡ä»¶ç¼ºå°‘'YL'æˆ–'SSub_JZg'åˆ—")
        
        if 'TS' in df_area.columns:
            pass
        elif 'SGen_JZg' in df_area.columns:
            df_area = df_area.rename(columns={'SGen_JZg': 'TS'})
        else:
            raise ValueError("åˆ¶å›¾æ–‡ä»¶ç¼ºå°‘'TS'æˆ–'SGen_JZg'åˆ—")
        
        required_cols_sample = ['TRZD', 'äºŒçº§åœ°ç±»', 'è¡Œæ”¿åŒºåç§°', 'YL', 'TS']
        required_cols_area = ['TRZD', 'äºŒçº§åœ°ç±»', 'è¡Œæ”¿åŒºåç§°', 'YL', 'TS', 'é¢ç§¯']

        for col in required_cols_sample:
            if col not in df_sample.columns:
                raise ValueError(f"æ ·ç‚¹æ–‡ä»¶ç¼ºå°‘åˆ—: {col}")
        for col in required_cols_area:
            if col not in df_area.columns:
                raise ValueError(f"åˆ¶å›¾æ–‡ä»¶ç¼ºå°‘åˆ—: {col}")

        # æ‰¹é‡æ˜ å°„ TRZD
        def safe_map(x):
            if pd.isna(x) or str(x).strip() in {"0", "/", ""}:
                return (None, None, None)
            s = str(x).strip()
            return TRZD_NAME_TO_INFO.get(s, ("å…¶ä»–", f"æœªçŸ¥({s})", 99))

        mapped_sample = df_sample['TRZD'].apply(safe_map)
        df_sample[['è´¨åœ°ç±»åˆ«', 'è´¨åœ°åç§°', 'åˆ†çº§']] = pd.DataFrame(mapped_sample.tolist(), index=df_sample.index)

        mapped_area = df_area['TRZD'].apply(safe_map)
        df_area[['è´¨åœ°ç±»åˆ«', 'è´¨åœ°åç§°', 'åˆ†çº§']] = pd.DataFrame(mapped_area.tolist(), index=df_area.index)

        # åˆ é™¤æ— æ•ˆè¡Œ
        df_sample = df_sample.dropna(subset=['è´¨åœ°ç±»åˆ«']).copy()
        df_area = df_area.dropna(subset=['è´¨åœ°ç±»åˆ«']).copy()

        # ç¡®ä¿é¢ç§¯ä¸ºæ•°å€¼
        df_area['é¢ç§¯'] = pd.to_numeric(df_area['é¢ç§¯'], errors='coerce')
        df_area = df_area.dropna(subset=['é¢ç§¯']).copy()

        total_sample_all = len(df_sample)
        total_area_all = df_area['é¢ç§¯'].sum()

        # ========== è¡¨1ï¼šæ€»ä½“çŠ¶å†µ ==========
        # æ•°å­—è½¬ç½—é©¬æ•°å­—æ˜ å°„
        grade_to_roman = {1: 'â… ', 2: 'â…¡', 3: 'â…¢', 4: 'â…£', 5: 'â…¤', 6: 'â…¥', 7: 'â…¦'}
        
        data1 = []
        VALID_GRADES = sorted(set(info[2] for info in TRZD_NAME_TO_INFO.values()))
        for grade in VALID_GRADES:
            names_in_grade = [n for n, (_, _, g) in TRZD_NAME_TO_INFO.items() if g == grade]
            cat_name = TRZD_NAME_TO_INFO[names_in_grade[0]][0]  # ç±»åˆ«åå–ç¬¬ä¸€ä¸ª
            roman_grade = grade_to_roman.get(grade, str(grade))  # è½¬ä¸ºç½—é©¬æ•°å­—
            
            for name in names_in_grade:
                count = len(df_sample[df_sample['è´¨åœ°åç§°'] == name])
                freq = round(count / total_sample_all * 100, 3) if total_sample_all > 0 else 0.0
                area_sum = df_area.loc[df_area['è´¨åœ°åç§°'] == name, 'é¢ç§¯'].sum()
                area_pct = round(area_sum / total_area_all * 100, 3) if total_area_all > 0 else 0.0
                data1.append([roman_grade, cat_name, name, count, freq, round(area_sum, 3), area_pct])

            # æ·»åŠ åˆè®¡ï¼ˆä»…å¯¹ 5,6,7ï¼‰
            if grade in [5, 6, 7]:
                subset_s = df_sample[df_sample['è´¨åœ°åç§°'].isin(names_in_grade)]
                subset_a = df_area[df_area['è´¨åœ°åç§°'].isin(names_in_grade)]
                count = len(subset_s)
                freq = round(count / total_sample_all * 100, 3) if total_sample_all > 0 else 0.0
                area_sum = subset_a['é¢ç§¯'].sum()
                area_pct = round(area_sum / total_area_all * 100, 3) if total_area_all > 0 else 0.0
                data1.append([roman_grade, cat_name, "åˆè®¡", count, freq, round(area_sum, 3), area_pct])

        data1.append(["å…¨å¸‚", "å…¨å¸‚", "å…¨å¸‚", total_sample_all, 100.0, round(total_area_all, 3), 100.0])

        df1 = pd.DataFrame(data1, columns=pd.MultiIndex.from_arrays([
            ["åœŸå£¤ä¸‰æ™®åˆ†çº§"] * 3 + ["æ ·ç‚¹ç»Ÿè®¡"] * 2 + ["åˆ¶å›¾ç»Ÿè®¡"] * 2,
            ["åˆ†çº§", "è´¨åœ°ç±»åˆ«", "è´¨åœ°åç§°", "é¢‘æ•°/ä¸ª", "é¢‘ç‡/%", "é¢ç§¯/äº©", "æ¯”ä¾‹/%"]
        ]))

        # ========== è¡¨2ï¼šåœŸåœ°åˆ©ç”¨ç±»å‹ ==========
        def get_land_class(dlmc):
            if pd.isna(dlmc):
                return (None, None)
            s = str(dlmc).strip()
            if s in ["æ°´ç”°", "æ°´æµ‡åœ°", "æ—±åœ°"]:
                return ("è€•åœ°", s)
            elif s in ["æœå›­", "èŒ¶å›­"]:
                return ("å›­åœ°", s)
            elif "å›­åœ°" in s:
                return ("å›­åœ°", "å…¶ä»–å›­åœ°")
            elif "æ—åœ°" in s:
                return ("æ—åœ°", "æ—åœ°")
            elif "è‰åœ°" in s:
                return ("è‰åœ°", "è‰åœ°")
            else:
                return ("å…¶ä»–", "å…¶ä»–")

        df_sample[['ä¸€çº§', 'äºŒçº§']] = pd.DataFrame(
            df_sample['äºŒçº§åœ°ç±»'].apply(get_land_class).tolist(),
            index=df_sample.index
        )
        df_area[['ä¸€çº§', 'äºŒçº§']] = pd.DataFrame(
            df_area['äºŒçº§åœ°ç±»'].apply(get_land_class).tolist(),
            index=df_area.index
        )

        land_config = {
            "è€•åœ°": ["æ°´ç”°", "æ°´æµ‡åœ°", "æ—±åœ°"],
            "å›­åœ°": ["æœå›­", "èŒ¶å›­", "å…¶ä»–å›­åœ°"],
            "æ—åœ°": ["æ—åœ°"],
            "è‰åœ°": ["è‰åœ°"],
            "å…¶ä»–": ["å…¶ä»–"]
        }

        data2 = []
        for primary, secondaries in land_config.items():
            for sec in secondaries:
                if primary in ["æ—åœ°", "è‰åœ°"]:
                    sample_sec = df_sample[df_sample['ä¸€çº§'] == primary]
                    area_sec = df_area[df_area['ä¸€çº§'] == primary]
                else:
                    sample_sec = df_sample[(df_sample['ä¸€çº§'] == primary) & (df_sample['äºŒçº§'] == sec)]
                    area_sec = df_area[(df_area['ä¸€çº§'] == primary) & (df_area['äºŒçº§'] == sec)]

                total_in_sec = len(sample_sec)
                total_area_sec = area_sec['é¢ç§¯'].sum()

                base_info = [primary, sec, round(total_area_sec, 3), total_in_sec]
                texture_data = build_texture_row(sample_sec, area_sec, total_in_sec, total_area_sec)
                data2.append(base_info + texture_data)

            if primary in ["è€•åœ°", "å›­åœ°"]:
                sample_total = df_sample[df_sample['ä¸€çº§'] == primary]
                area_total = df_area[df_area['ä¸€çº§'] == primary]
                total_count_p = len(sample_total)
                total_area_p = area_total['é¢ç§¯'].sum()

                base_info = ["", "åˆè®¡", round(total_area_p, 3), total_count_p]
                texture_data = build_texture_row(sample_total, area_total, total_count_p, total_area_p)
                data2.append(base_info + texture_data)

        city_base = ["å…¨å¸‚", "å…¨å¸‚", round(total_area_all, 3), total_sample_all]
        city_texture = build_texture_row(df_sample, df_area, total_sample_all, total_area_all)
        data2.append(city_base + city_texture)

        df2 = pd.DataFrame(data2, columns=pd.MultiIndex.from_arrays([HEADER_TOP_2, HEADER_BOT_2]))
        
        # è®°å½•éœ€è¦åˆå¹¶çš„è¡Œä¿¡æ¯ï¼ˆä¸€çº§åˆ†ç±»ï¼‰
        merge_info_land = []  # [(start_row, end_row, primary_name), ...]

        # è®°å½•åœŸåœ°åˆ©ç”¨ç±»å‹çš„ä¸€çº§åˆ†ç±»åˆå¹¶ä¿¡æ¯
        current_row_idx = 0
        for primary, secondaries in land_config.items():
            start_row = current_row_idx
            current_row_idx += len(secondaries)
            if primary in ["è€•åœ°", "å›­åœ°"]:
                current_row_idx += 1  # åˆè®¡è¡Œ
            end_row = current_row_idx - 1
            merge_info_land.append((start_row, end_row, primary))
        
        # ========== è¡¨3ï¼šä¸åŒåœŸå£¤ç±»å‹ ==========
        # æ”¶é›†æ‰€æœ‰äºšç±»å’ŒåœŸå±ï¼ˆä¸æ’åºï¼Œåç»­ç»Ÿä¸€æŒ‰é¢„å®šä¹‰é¡ºåºæ’åºï¼‰
        sub_to_gens = df_sample.groupby('YL')['TS'].apply(
            lambda x: list(x.dropna().unique())
        ).to_dict()

        sub_to_gens_area = df_area.groupby('YL')['TS'].apply(
            lambda x: list(x.dropna().unique())
        ).to_dict()

        all_sub_gens = {}
        all_subs = set(sub_to_gens.keys()) | set(sub_to_gens_area.keys())
        for sub in all_subs:
            gens_s = set(sub_to_gens.get(sub, []))
            gens_a = set(sub_to_gens_area.get(sub, []))
            all_sub_gens[sub] = list(gens_s | gens_a)  # è½¬ä¸ºåˆ—è¡¨ï¼Œä¸æ’åº
        
        # åœŸå£¤ç±»å‹æ’åºæ˜ å°„è¡¨ï¼ˆåŸºäºå®é™…æ•°æ®æ›´æ–°ï¼‰
        soil_type_order_map = {
            'æ£•çº¢å£¤': ['çº¢æ³¥è´¨æ£•çº¢å£¤'],
            'çº¢å£¤æ€§åœŸ': ['ç ‚æ³¥è´¨çº¢å£¤æ€§åœŸ', 'éº»ç ‚è´¨çº¢å£¤æ€§åœŸ'],
            'å…¸å‹é»„æ£•å£¤': ['æš—æ³¥è´¨é»„æ£•å£¤', 'éº»ç ‚è´¨é»„æ£•å£¤', 'çº¢ç ‚è´¨é»„æ£•å£¤', 'é»„åœŸè´¨é»„æ£•å£¤', 'ç ‚æ³¥è´¨é»„æ£•å£¤'],
            'é»„æ£•å£¤æ€§åœŸ': ['ç ‚æ³¥è´¨é»„æ£•å£¤æ€§åœŸ'],
            'å…¸å‹æ£•å£¤': ['éº»ç ‚è´¨å…¸å‹æ£•å£¤'],
            'ç™½æµ†åŒ–æ£•å£¤': ['éº»ç ‚è´¨ç™½æµ†åŒ–æ£•å£¤', 'æ³¥ç ‚è´¨ç™½æµ†åŒ–æ£•å£¤'],
            'æ½®æ£•å£¤': ['æ³¥ç ‚è´¨æ½®æ£•å£¤'],
            'æ·‹æº¶è¤åœŸ': ['é»„åœŸè´¨æ·‹æº¶è¤åœŸ', 'ç°æ³¥è´¨æ·‹æº¶è¤åœŸ', 'æš—æ³¥è´¨æ·‹æº¶è¤åœŸ'],
            'æ½®è¤åœŸ': ['æ³¥ç ‚è´¨æ½®è¤åœŸ'],
            'çº¢é»åœŸ': ['çº¢é»åœŸ'],
            'é»‘è‰²çŸ³ç°åœŸ': ['é»‘è‰²çŸ³ç°åœŸ'],
            'æ£•è‰²çŸ³ç°åœŸ': ['æ£•è‰²çŸ³ç°åœŸ'],
            'æš—ç«å±±ç°åœŸ': ['æš—ç«å±±ç°åœŸ'],
            'é…¸æ€§ç´«è‰²åœŸ': ['å£¤è´¨é…¸æ€§ç´«è‰²åœŸ', 'é»è´¨é…¸æ€§ç´«è‰²åœŸ'],
            'ä¸­æ€§ç´«è‰²åœŸ': ['ç ‚è´¨ä¸­æ€§ç´«è‰²åœŸ', 'å£¤è´¨ä¸­æ€§ç´«è‰²åœŸ', 'é»è´¨ä¸­æ€§ç´«è‰²åœŸ'],
            'çŸ³ç°æ€§ç´«è‰²åœŸ': ['å£¤è´¨çŸ³ç°æ€§ç´«è‰²åœŸ'],
            'é…¸æ€§ç²—éª¨åœŸ': ['éº»ç ‚è´¨é…¸æ€§ç²—éª¨åœŸ', 'ç¡…è´¨é…¸æ€§ç²—éª¨åœŸ'],
            'ä¸­æ€§ç²—éª¨åœŸ': ['éº»ç ‚è´¨ä¸­æ€§ç²—éª¨åœŸ'],
            'é’™è´¨ç²—éª¨åœŸ': ['ç°æ³¥è´¨é’™è´¨ç²—éª¨åœŸ'],
            'å…¸å‹æ½®åœŸ': ['ç ‚è´¨æ½®åœŸ', 'å£¤è´¨æ½®åœŸ', 'é»è´¨æ½®åœŸ'],
            'ç°æ½®åœŸ': ['ç°æ½®åœŸ', 'çŸ³ç°æ€§ç°æ½®åœŸ'],
            'ç›åŒ–æ½®åœŸï¼ˆå«ç¢±åŒ–æ½®åœŸï¼‰': ['æ°¯åŒ–ç‰©ç›åŒ–æ½®åœŸ', 'ç¡«é…¸ç›ç›åŒ–æ½®åœŸ', 'è‹æ‰“ç›åŒ–æ½®åœŸ'],
            'å…¸å‹ç ‚å§œé»‘åœŸ': ['é»‘è…ç ‚å§œé»‘åœŸï¼ˆé»‘å§œåœŸï¼‰', 'è¦†æ³¥ç ‚å§œé»‘åœŸï¼ˆè¦†æ³¥é»‘å§œåœŸï¼‰'],
            'ç›åŒ–ç ‚å§œé»‘åœŸ': ['æ°¯åŒ–ç‰©ç›åŒ–ç ‚å§œé»‘åœŸ'],
            'è…æ³¥æ²¼æ³½åœŸ': ['è…æ³¥æ²¼æ³½åœŸ'],
            'è‰ç”¸æ²¼æ³½åœŸ': ['è‰ç”¸æ²¼æ³½åœŸ', 'çŸ³ç°æ€§è‰ç”¸æ²¼æ³½åœŸ'],
            'å…¸å‹æ»¨æµ·ç›åœŸ': ['æ°¯åŒ–ç‰©æ»¨æµ·ç›åœŸ'],
            'æ»¨æµ·æ²¼æ³½ç›åœŸ': ['æ°¯åŒ–ç‰©æ²¼æ³½æ»¨æµ·ç›åœŸ'],
            'æ»¨æµ·æ½®æ»©ç›åœŸ': ['æ°¯åŒ–ç‰©æ½®æ»©æ»¨æµ·ç›åœŸ'],
            'æ·¹è‚²æ°´ç¨»åœŸ': ['æµ…é©¬è‚æ³¥ç”°'],
            'æ¸—è‚²æ°´ç¨»åœŸ': ['æ¸—ç°æ³¥ç”°', 'æ¸—æ½®æ³¥ç ‚ç”°', 'æ¸—æ½®æ³¥ç”°', 'æ¸—æ¹–æ³¥ç”°', 'æ¸—æ¶‚æ³¥ç”°', 'æ¸—æ·¡æ¶‚æ³¥ç”°', 'æ¸—éº»ç ‚æ³¥ç”°', 'æ¸—æ½®ç™½åœŸç”°', 'æ¸—é©¬è‚æ³¥ç”°'],
            'æ½´è‚²æ°´ç¨»åœŸ': ['æ½®æ³¥ç”°', 'æ¹–æ³¥ç”°', 'é©¬è‚æ³¥ç”°'],
            'æ½œè‚²æ°´ç¨»åœŸ': ['é’æ¹–æ³¥ç”°', 'é’é©¬è‚æ³¥ç”°'],
            'è„±æ½œæ°´ç¨»åœŸ': ['é»„æ–‘é»ç”°', 'é»„æ–‘æ³¥ç”°'],
            'æ¼‚æ´—æ°´ç¨»åœŸ': ['æ¼‚æ½®ç™½åœŸç”°', 'æ¼‚é©¬è‚æ³¥ç”°'],
            'ç›æ¸æ°´ç¨»åœŸ': ['æ°¯åŒ–ç‰©æ½®æ³¥ç”°', 'æ°¯åŒ–ç‰©æ¶‚æ³¥ç”°', 'æ°¯åŒ–ç‰©æ¹–æ³¥ç”°', 'ç¡«é…¸ç›æ½®æ³¥ç”°', 'ç¡«é…¸ç›æ¶‚æ³¥ç”°', 'è‹æ‰“æ½®æ³¥ç”°', 'è‹æ‰“æ¶‚æ³¥ç”°', 'è‹æ‰“æ¹–æ³¥ç”°'],
            'å¡«å……åœŸ': ['å·¥çŸ¿å¡«å……åœŸ', 'åŸé•‡å¡«å……åœŸ'],
            'æ‰°åŠ¨åœŸ': ['è¿ç§»æ‰°åŠ¨åœŸ']
        }
        
        # ç”Ÿæˆäºšç±»æ’åºåˆ—è¡¨ï¼ˆæŒ‰æ˜ å°„è¡¨é¡ºåºï¼‰
        sub_order = list(soil_type_order_map.keys())
        
        def get_soil_order(soil_name):
            """è·å–åœŸå£¤ç±»å‹çš„æ’åºç´¢å¼•"""
            try:
                return sub_order.index(soil_name)
            except ValueError:
                return len(sub_order)  # æœªåœ¨åˆ—è¡¨ä¸­çš„æ’åˆ°æœ€å
        
        # æŒ‰åœŸå£¤ç±»å‹æ’åºäºšç±»ï¼ˆå…ˆæŒ‰é¢„å®šä¹‰é¡ºåºï¼‰
        sorted_subs = sorted(all_sub_gens.keys(), key=get_soil_order)
        
        # å¯¹æ¯ä¸ªäºšç±»ä¸‹çš„åœŸå±æŒ‰é¢„å®šä¹‰é¡ºåºæ’åº
        sorted_all_sub_gens = {}
        for sub in sorted_subs:
            gen_list = all_sub_gens[sub]
            if sub in soil_type_order_map:
                # ä½¿ç”¨é¢„å®šä¹‰é¡ºåºæ’åº
                predefined_order = soil_type_order_map[sub]
                def get_gen_order(gen_name):
                    try:
                        return predefined_order.index(gen_name)
                    except ValueError:
                        return len(predefined_order)  # æœªåœ¨åˆ—è¡¨ä¸­çš„æ’åˆ°æœ€å
                sorted_all_sub_gens[sub] = sorted(gen_list, key=get_gen_order)
            else:
                # æ²¡æœ‰é¢„å®šä¹‰é¡ºåºçš„ï¼ŒæŒ‰å­—ç¬¦ä¸²æ’åº
                sorted_all_sub_gens[sub] = sorted(gen_list)
        
        # é‡æ–°æ„å»ºæœ‰åºå­—å…¸ï¼ˆä¿æŒäºšç±»é¡ºåºï¼‰
        all_sub_gens = {sub: sorted_all_sub_gens[sub] for sub in sorted_subs}

        data3 = []
        # æŒ‰æ’åºåçš„äºšç±»é¡ºåºéå†ï¼ˆç¡®ä¿é¡ºåºæ­£ç¡®ï¼‰
        for sub in sorted_subs:
            gens = all_sub_gens[sub]
            for gen in gens:
                sample_soil = df_sample[(df_sample['YL'] == sub) & (df_sample['TS'] == gen)]
                area_soil = df_area[(df_area['YL'] == sub) & (df_area['TS'] == gen)]

                total_count = len(sample_soil)
                total_area_val = area_soil['é¢ç§¯'].sum()

                base_info = [sub, gen, round(total_area_val, 3), total_count]
                texture_data = build_texture_row(sample_soil, area_soil, total_count, total_area_val)
                data3.append(base_info + texture_data)

            if len(gens) >= 2:
                sample_sub = df_sample[df_sample['YL'] == sub]
                area_sub = df_area[df_area['YL'] == sub]
                total_count_sub = len(sample_sub)
                total_area_sub = area_sub['é¢ç§¯'].sum()
                base_info_sub = [sub, "åˆè®¡", round(total_area_sub, 3), total_count_sub]
                texture_data_sub = build_texture_row(sample_sub, area_sub, total_count_sub, total_area_sub)
                data3.append(base_info_sub + texture_data_sub)

        city_base = ["å…¨å¸‚", "å…¨å¸‚", round(total_area_all, 3), total_sample_all]
        data3.append(city_base + city_texture)

        df3 = pd.DataFrame(data3, columns=pd.MultiIndex.from_arrays([HEADER_TOP_3, HEADER_BOT_3]))
        
        # è®°å½•åœŸå£¤ç±»å‹çš„äºšç±»åˆå¹¶ä¿¡æ¯
        merge_info_soil = []  # [(start_row, end_row, sub_name), ...]
        current_row_idx_soil = 0
        # æŒ‰æ’åºåçš„äºšç±»é¡ºåºéå†ï¼ˆä¸data3ä¿æŒä¸€è‡´ï¼‰
        for sub in sorted_subs:
            gens = all_sub_gens[sub]
            start_row = current_row_idx_soil
            current_row_idx_soil += len(gens)
            if len(gens) >= 2:
                current_row_idx_soil += 1  # åˆè®¡è¡Œ
            end_row = current_row_idx_soil - 1
            merge_info_soil.append((start_row, end_row, sub))

        # ========== è¡¨4ï¼šå„ä¹¡é•‡ ==========
        towns = sorted(set(df_sample['è¡Œæ”¿åŒºåç§°'].dropna()) | set(df_area['è¡Œæ”¿åŒºåç§°'].dropna()), key=get_pinyin_first_letter)
        data4 = []

        for town in towns:
            s_town = df_sample[df_sample['è¡Œæ”¿åŒºåç§°'] == town]
            a_town = df_area[df_area['è¡Œæ”¿åŒºåç§°'] == town]

            total_count = len(s_town)
            total_area_val = a_town['é¢ç§¯'].sum()

            base_info = [town, round(total_area_val, 3), total_count]
            texture_data = build_texture_row(s_town, a_town, total_count, total_area_val)
            data4.append(base_info + texture_data)

        city_base_town = ["å…¨å¸‚", round(total_area_all, 3), total_sample_all]
        data4.append(city_base_town + city_texture)
        df4 = pd.DataFrame(data4, columns=pd.MultiIndex.from_arrays([HEADER_TOP_4, HEADER_BOT_4]))

        # ========== å¯¼å‡º ==========
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"åœŸå£¤è´¨åœ°ç»Ÿè®¡_{timestamp}.xlsx"

        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            df1.to_excel(writer, sheet_name="æ€»ä½“çŠ¶å†µ-åœŸå£¤è´¨åœ°åˆ†ç±»", index=True, startrow=0)
            df2.to_excel(writer, sheet_name="ä¸åŒåœŸåœ°åˆ©ç”¨ç±»å‹åœŸå£¤è´¨åœ°", index=True, startrow=0)
            df3.to_excel(writer, sheet_name="ä¸åŒåœŸå£¤ç±»å‹åœŸå£¤è´¨åœ°", index=True, startrow=0)
            df4.to_excel(writer, sheet_name="å„ä¹¡é•‡åœŸå£¤è´¨åœ°", index=True, startrow=0)

            wb = writer.book
            
            # ========== åˆ é™¤ç¬¬3è¡Œç©ºè¡Œ ==========
            for sheet_name in wb.sheetnames:
                ws = wb[sheet_name]
                # åˆ é™¤ç¬¬3è¡Œï¼ˆpandaså¤šçº§è¡¨å¤´å¯¼è‡´çš„ç©ºè¡Œï¼‰
                ws.delete_rows(3, 1)
            
            # ========== å¤„ç†è¡¨1ï¼šåˆå¹¶è´¨åœ°ç±»åˆ«å•å…ƒæ ¼ ==========
            ws1 = wb["æ€»ä½“çŠ¶å†µ-åœŸå£¤è´¨åœ°åˆ†ç±»"]
            # æ‰¾åˆ°è´¨åœ°ç±»åˆ«åˆ—ï¼ˆç¬¬Cåˆ—ï¼‰
            cat_col_letter = 'C'
            row_start = 3  # åˆ é™¤ç©ºè¡Œåï¼Œæ•°æ®ä»ç¬¬3è¡Œå¼€å§‹
            
            # æŒ‰è´¨åœ°ç±»åˆ«åˆ†ç»„åˆå¹¶
            current_cat = None
            cat_start_row = None
            for row_idx in range(row_start, row_start + len(data1) + 1):
                if row_idx < row_start + len(data1):
                    cell_value = ws1[f'{cat_col_letter}{row_idx}'].value
                    if cell_value != current_cat:
                        # åˆå¹¶ä¸Šä¸€ä¸ªç±»åˆ«
                        if current_cat is not None and cat_start_row is not None and row_idx > cat_start_row:
                            ws1.merge_cells(f'{cat_col_letter}{cat_start_row}:{cat_col_letter}{row_idx - 1}')
                            ws1[f'{cat_col_letter}{cat_start_row}'].alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center')
                        # å¼€å§‹æ–°ç±»åˆ«
                        current_cat = cell_value
                        cat_start_row = row_idx
                else:
                    # å¤„ç†æœ€åä¸€ä¸ªç±»åˆ«
                    if current_cat is not None and cat_start_row is not None and row_idx > cat_start_row:
                        ws1.merge_cells(f'{cat_col_letter}{cat_start_row}:{cat_col_letter}{row_idx - 1}')
                        ws1[f'{cat_col_letter}{cat_start_row}'].alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center')
            
            # ========== å¤„ç†è¡¨2ï¼šåˆå¹¶åœŸåœ°åˆ©ç”¨ç±»å‹ä¸€çº§åˆ†ç±» ==========
            ws2 = wb["ä¸åŒåœŸåœ°åˆ©ç”¨ç±»å‹åœŸå£¤è´¨åœ°"]
            # ä¸€çº§åˆ†ç±»åœ¨ç¬¬Båˆ—ï¼ˆExcelåˆ—ï¼Œä¸æ˜¯ç´¢å¼•ï¼‰
            primary_col_letter = 'B'
            secondary_col_letter = 'C'
            data_start_row = 3  # æ•°æ®ä»ç¬¬3è¡Œå¼€å§‹
            
            for start_idx, end_idx, primary_name in merge_info_land:
                start_row = data_start_row + start_idx
                end_row = data_start_row + end_idx
                
                # æ£€æŸ¥æ˜¯å¦ä¸€çº§=äºŒçº§ï¼ˆå¦‚æ—åœ°-æ—åœ°ï¼‰
                if primary_name in ["æ—åœ°", "è‰åœ°", "å…¶ä»–"]:
                    # åˆå¹¶ä¸€çº§å’ŒäºŒçº§åˆ—ï¼ˆBå’ŒCåˆ—ï¼‰
                    ws2.merge_cells(f'{primary_col_letter}{start_row}:{secondary_col_letter}{start_row}')
                    ws2[f'{primary_col_letter}{start_row}'].alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center')
                else:
                    # åˆå¹¶ä¸€çº§åˆ—ï¼ˆä»…Båˆ—ï¼‰
                    if end_row > start_row:
                        ws2.merge_cells(f'{primary_col_letter}{start_row}:{primary_col_letter}{end_row}')
                        ws2[f'{primary_col_letter}{start_row}'].alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center')
            
            # ========== å¤„ç†è¡¨3ï¼šåˆå¹¶åœŸå£¤ç±»å‹äºšç±» ==========
            ws3 = wb["ä¸åŒåœŸå£¤ç±»å‹åœŸå£¤è´¨åœ°"]
            # äºšç±»åœ¨ç¬¬Båˆ—
            sub_col_letter = 'B'
            data_start_row_soil = 3
            
            for start_idx, end_idx, sub_name in merge_info_soil:
                start_row = data_start_row_soil + start_idx
                end_row = data_start_row_soil + end_idx
                if end_row > start_row:
                    ws3.merge_cells(f'{sub_col_letter}{start_row}:{sub_col_letter}{end_row}')
                    ws3[f'{sub_col_letter}{start_row}'].alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center')
            
            # ========== ä¸ºæ‰€æœ‰è¡¨æ ¼æ·»åŠ å±…ä¸­å¯¹é½ ==========
            for sheet_name in wb.sheetnames:
                ws = wb[sheet_name]
                for row in ws.iter_rows():
                    for cell in row:
                        if cell.value is not None:
                            cell.alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center')
            
            # éšè—ç´¢å¼•åˆ—
            for ws_name in wb.sheetnames:
                ws = wb[ws_name]
                ws.column_dimensions['A'].hidden = True
            
            wb.save(output_file)

        return True, output_file

    except Exception as e:
        return False, str(e)


# ========== GUI ==========
class App:
    def __init__(self, root):
        self.root = root
        self.root.title("åœŸå£¤è´¨åœ°(TRZD)ç»Ÿè®¡å·¥å…·")
        self.root.geometry("580x320")
        self.sample_file = None
        self.area_files = None  # æ”¯æŒå¤šä¸ªåˆ¶å›¾æ–‡ä»¶

        tk.Label(root, text="åœŸå£¤è´¨åœ°(TRZD)åˆ†å¸ƒç»Ÿè®¡", font=("Arial", 14, "bold")).pack(pady=10)
        tk.Label(root,
                 text="â€¢ æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼šTRZD, äºŒçº§åœ°ç±»(æˆ–DLMC), è¡Œæ”¿åŒºåç§°, YL(æˆ–SSub_JZg), TS(æˆ–SGen_JZg)\nâ€¢ åˆ¶å›¾æ–‡ä»¶é¢å¤–éœ€å«ï¼šé¢ç§¯\nâ€¢ TRZD ä¸ºä¸­æ–‡è´¨åœ°åç§°ï¼ˆå¦‚'å£¤åœŸ'ï¼‰ï¼Œ'0'ã€'/'ã€ç©ºå€¼å°†è¢«å¿½ç•¥",
                 fg="gray").pack()

        tk.Button(root, text="ğŸ“ é€‰æ‹©ã€æ ·ç‚¹ç»Ÿè®¡.csvã€‘", command=self.select_sample).pack(pady=6)
        self.label_sample = tk.Label(root, text="æœªé€‰æ‹©", fg="gray")
        self.label_sample.pack()

        tk.Button(root, text="ğŸ“ é€‰æ‹©ã€åˆ¶å›¾ç»Ÿè®¡.csvã€‘ï¼ˆå¯å¤šé€‰ï¼‰", command=self.select_area).pack(pady=6)
        self.label_area = tk.Label(root, text="æœªé€‰æ‹©", fg="gray")
        self.label_area.pack()

        tk.Button(root, text="âœ… ç”Ÿæˆç»Ÿè®¡è¡¨", command=self.run_process, bg="#4CAF50", fg="white",
                  font=("Arial", 12)).pack(pady=15)

    def select_sample(self):
        f = filedialog.askopenfilename(filetypes=[("CSV files", "*.csv")])
        if f:
            self.sample_file = f
            self.label_sample.config(text=f.split("/")[-1], fg="black")

    def select_area(self):
        files = filedialog.askopenfilenames(filetypes=[("CSV files", "*.csv")])
        if files:
            self.area_files = list(files)
            names = [f.split("/")[-1] for f in files]
            if len(names) <= 3:
                display = ", ".join(names)
            else:
                display = f"{len(names)} ä¸ªæ–‡ä»¶ï¼ˆ{', '.join(names[:2])}...ï¼‰"
            self.label_area.config(text=display, fg="black")

    def run_process(self):
        if not self.sample_file or not self.area_files:
            messagebox.showwarning("âš ï¸ æç¤º", "è¯·å…ˆé€‰æ‹©æ ·ç‚¹æ–‡ä»¶å’Œè‡³å°‘ä¸€ä¸ªåˆ¶å›¾æ–‡ä»¶ï¼")
            return

        success, msg = process_trzd_files(self.sample_file, self.area_files, "")
        if success:
            messagebox.showinfo("ğŸ‰ æˆåŠŸ", f"æ–‡ä»¶å·²ç”Ÿæˆï¼š\n{msg}")
        else:
            messagebox.showerror("âŒ é”™è¯¯", f"å¤„ç†å¤±è´¥ï¼š\n{msg}")


if __name__ == "__main__":
    root = tk.Tk()
    app = App(root)
    root.mainloop()