import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import pandas as pd
import chardet
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, Border, Side
from openpyxl.utils import get_column_letter
import numpy as np
from datetime import datetime
import math

SOIL_ATTR_CONFIG = {
    # ========== è¡¨3ï¼šåœŸå£¤å±æ€§åˆ†çº§æ ‡å‡† ==========
    'SRXYZL': {
        'name': 'æ°´æº¶æ€§ç›æ€»é‡',
        'unit': 'g/kg',
        'reverse_display': False,
        'levels': [
            (1, '1çº§', 'æ— ç›åŒ–'),
            (2, '2çº§', 'è½»åº¦ç›åŒ–'),
            (4, '3çº§', 'ä¸­åº¦ç›åŒ–'),
            (6, '4çº§', 'é‡åº¦ç›åŒ–'),
            (float('inf'), '5çº§', 'ç›åœŸ')
        ]
    },
    'DDL': {
        'name': 'ç”µå¯¼ç‡',
        'unit': 'mS/cm',
        'reverse_display': False,
        'levels': [
            (0.4, '1çº§', 'ä½'),
            (0.8, '2çº§', 'è¾ƒä½'),
            (1.6, '3çº§', 'ä¸­'),
            (2.4, '4çº§', 'è¾ƒé«˜'),
            (float('inf'), '5çº§', 'é«˜')
        ]
    },
    'ENA': {
        'name': 'äº¤æ¢æ€§é’ ',
        'unit': 'cmol(+)/kg',
        'reverse_display': False,
        'levels': [
            (0.2, '1çº§', 'ä½'),
            (0.5, '2çº§', 'è¾ƒä½'),
            (0.8, '3çº§', 'ä¸­'),
            (1.2, '4çº§', 'è¾ƒé«˜'),
            (float('inf'), '5çº§', 'é«˜')
        ]
    },

    'TRRZPJZ': {
        'name': 'åœŸå£¤å®¹é‡',
        'unit': 'g/cmÂ³',
        'reverse_display': False,
        'levels': [
            (0.9, '1çº§', 'ä¸é€‚å®œ'),
            (1.1, '2çº§', 'è¾ƒé€‚å®œ'),
            (1.35, '3çº§', 'é€‚å®œ'),
            (1.55, '4çº§', 'è¾ƒé€‚å®œ'),
            (float('inf'), '5çº§', 'ä¸é€‚å®œ')
        ]
    },

    'GZCHD': {
        'name': 'è€•ä½œå±‚åšåº¦',
        'unit': 'cm',
        'reverse_display': True,
        'levels': [
            (10, '5çº§', 'è–„'),
            (15, '4çº§', 'è¾ƒè–„'),
            (20, '3çº§', 'ä¸­'),
            (25, '2çº§', 'è¾ƒåš'),
            (float('inf'), '1çº§', 'åš')
        ]
    },

    'EK': {
        'name': 'äº¤æ¢æ€§é’¾',
        'unit': '',
        'reverse_display': False,
        'levels': [
            (0.1, '1çº§', 'æ— æ•ˆé’¾'),
            (0.2, '2çº§', 'ä½æ•ˆé’¾'),
            (0.4, '3çº§', 'ä¸­æ•ˆé’¾'),
            (float('inf'), '4çº§', 'é«˜æ•ˆé’¾')
        ]
    },
    'JHXYJZL': {
        'name': 'äº¤æ¢æ€§ç›åŸºæ€»é‡',
        'unit': 'cmol(+)/kg',
        'reverse_display': False,
        'levels': [
            (5, '1çº§', 'ä½'),
            (10, '2çº§', 'è¾ƒä½'),
            (15, '3çº§', 'ä¸­'),
            (20, '4çº§', 'è¾ƒé«˜'),
            (float('inf'), '5çº§', 'é«˜')
        ]
    },
    'åœ°è¡¨ç ¾çŸ³ä¸°åº¦': {
        'name': 'åœ°è¡¨ç ¾çŸ³ä¸°åº¦',
        'unit': '',
        'reverse_display': True,
        'levels': [
            (float('inf'), '1çº§', 'æ— ')  # å®šæ€§æè¿°ï¼Œä¿ç•™å ä½
        ]
    },
    'SWXDTJT7': {
        'name': 'æ°´ç¨³æ€§å¤§å›¢èšä½“',
        'unit': 'mg/kg',
        'reverse_display': False,
        'levels': [
            (10, '1çº§', 'ä½'),
            (20, '2çº§', 'è¾ƒä½'),
            (30, '3çº§', 'ä¸­'),
            (40, '4çº§', 'è¾ƒé«˜'),
            (float('inf'), '5çº§', 'é«˜')
        ]
    },
    'OM': {
        'name': 'æœ‰æœºè´¨',
        'unit': 'g/kg',
        'reverse_display': True,
        'levels': [
            (10, '5çº§', 'ä½'),
            (20, '4çº§', 'è¾ƒä½'),
            (30, '3çº§', 'ä¸­'),
            (40, '2çº§', 'è¾ƒé«˜'),
            (float('inf'), '1çº§', 'é«˜')
        ]
    },
    'CEC': {
        'name': 'é˜³ç¦»å­äº¤æ¢é‡',
        'unit': 'cmol(+)/kg',
        'reverse_display': False,
        'levels': [
            (5, '5çº§', 'ä½'),
            (10, '4çº§', 'è¾ƒä½'),
            (15, '3çº§', 'ä¸­'),
            (20, '2çº§', 'è¾ƒé«˜'),
            (float('inf'), '1çº§', 'é«˜')
        ]
    },
    'ç¢³é…¸é’™': {
        'name': 'ç¢³é…¸é’™',
        'unit': 'g/kg',
        'reverse_display': True,
        'levels': [
            (10, '5çº§', 'ä½'),
            (30, '4çº§', 'è¾ƒä½'),
            (50, '3çº§', 'ä¸­'),
            (150, '2çº§', 'è¾ƒé«˜'),
            (float('inf'), '1çº§', 'é«˜')
        ]
    },
    'TN': {
        'name': 'å…¨æ°®',
        'unit': 'g/kg',
        'reverse_display': True,
        'levels': [
            (0.5, '5çº§', 'æç¼º'),
            (1.0, '4çº§', 'ç¼ºä¹'),
            (1.5, '3çº§', 'ä¸­ç­‰'),
            (2.0, '2çº§', 'è¾ƒä¸°å¯Œ'),
            (float('inf'), '1çº§', 'ä¸°å¯Œ')
        ]
    },
    'TP': {
        'name': 'å…¨ç£·',
        'unit': 'g/kg',
        'reverse_display': True,
        'levels': [
            (0.4, '5çº§', 'æç¼º'),
            (0.6, '4çº§', 'ç¼ºä¹'),
            (0.8, '3çº§', 'ä¸­ç­‰'),
            (1.0, '2çº§', 'è¾ƒä¸°å¯Œ'),
            (float('inf'), '1çº§', 'ä¸°å¯Œ')
        ]
    },
    'TK': {
        'name': 'å…¨é’¾',
        'unit': 'g/kg',
        'reverse_display': True,
        'levels': [
            (10, '5çº§', 'æç¼º'),
            (15, '4çº§', 'ç¼ºä¹'),
            (20, '3çº§', 'ä¸­ç­‰'),
            (25, '2çº§', 'è¾ƒä¸°å¯Œ'),
            (float('inf'), '1çº§', 'ä¸°å¯Œ')
        ]
    },
    'AP': {
        'name': 'æœ‰æ•ˆç£·',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (5, '5çº§', 'æç¼º'),
            (10, '4çº§', 'ç¼ºä¹'),
            (20, '3çº§', 'ä¸­ç­‰'),
            (40, '2çº§', 'è¾ƒä¸°å¯Œ'),
            (float('inf'), '1çº§', 'ä¸°å¯Œ')
        ]
    },
    'AK': {
        'name': 'é€Ÿæ•ˆé’¾',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (50, '5çº§', 'æç¼º'),
            (100, '4çº§', 'ç¼ºä¹'),
            (150, '3çº§', 'ä¸­ç­‰'),
            (200, '2çº§', 'è¾ƒä¸°å¯Œ'),
            (float('inf'), '1çº§', 'ä¸°å¯Œ')
        ]
    },
    'SK': {
        'name': 'ç¼“æ•ˆé’¾',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (100, '5çº§', 'æç¼º'),
            (300, '4çº§', 'ç¼ºä¹'),
            (500, '3çº§', 'ä¸­ç­‰'),
            (700, '2çº§', 'è¾ƒä¸°å¯Œ'),
            (float('inf'), '1çº§', 'ä¸°å¯Œ')
        ]
    },
    'ECA': {
        'name': 'äº¤æ¢æ€§é’™',
        'unit': 'cmol(1/2CaÂ²âº)/kg',
        'reverse_display': True,
        'levels': [
            (1.0, '5çº§', 'æç¼º'),
            (4.0, '4çº§', 'ç¼ºä¹'),
            (10.0, '3çº§', 'ä¸­ç­‰'),
            (15.0, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },
    'EMG': {
        'name': 'äº¤æ¢æ€§é•',
        'unit': 'cmol(1/2MgÂ²âº)/kg',
        'reverse_display': True,
        'levels': [
            (0.5, '5çº§', 'æç¼º'),
            (1.0, '4çº§', 'ç¼ºä¹'),
            (1.5, '3çº§', 'ä¸­ç­‰'),
            (2.0, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },
    'AS1': {
        'name': 'æœ‰æ•ˆç¡«',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (10.0, '5çº§', 'æç¼º'),
            (20.0, '4çº§', 'ç¼ºä¹'),
            (30.0, '3çº§', 'ä¸­ç­‰'),
            (40.0, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },
    'ASI': {
        'name': 'æœ‰æ•ˆç¡…',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (50, '5çº§', 'æç¼º'),
            (100, '4çº§', 'ç¼ºä¹'),
            (150, '3çº§', 'ä¸­ç­‰'),
            (250, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },
    'AFE': {
        'name': 'æœ‰æ•ˆé“',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (2.5, '5çº§', 'æç¼º'),
            (4.5, '4çº§', 'ç¼ºä¹'),
            (10.0, '3çº§', 'ä¸­ç­‰'),
            (20.0, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },
    'AMN': {
        'name': 'æœ‰æ•ˆé”°',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (1.0, '5çº§', 'æç¼º'),
            (5.0, '4çº§', 'ç¼ºä¹'),
            (15.0, '3çº§', 'ä¸­ç­‰'),
            (30.0, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },
    'ACU': {
        'name': 'æœ‰æ•ˆé“œ',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (0.2, '5çº§', 'æç¼º'),
            (0.5, '4çº§', 'ç¼ºä¹'),
            (1.0, '3çº§', 'ä¸­ç­‰'),
            (2.0, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },
    'AZN': {
        'name': 'æœ‰æ•ˆé”Œ',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (0.5, '5çº§', 'æç¼º'),
            (1.0, '4çº§', 'ç¼ºä¹'),
            (2.0, '3çº§', 'ä¸­ç­‰'),
            (3.0, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },
    'AB': {
        'name': 'æœ‰æ•ˆç¡¼',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (0.2, '5çº§', 'æç¼º'),
            (0.5, '4çº§', 'ç¼ºä¹'),
            (1.0, '3çº§', 'ä¸­ç­‰'),
            (2.0, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },
    'AMO': {
        'name': 'æœ‰æ•ˆé’¼',
        'unit': 'mg/kg',
        'reverse_display': True,
        'levels': [
            (0.10, '5çº§', 'æç¼º'),
            (0.15, '4çº§', 'ç¼ºä¹'),
            (0.20, '3çº§', 'ä¸­ç­‰'),
            (0.30, '2çº§', 'ä¸°å¯Œ'),
            (float('inf'), '1çº§', 'åé«˜')
        ]
    },

    # ========== è¡¨4ï¼šåœŸå£¤ pH å€¼åˆ†çº§æ ‡å‡† ==========
    'ph': {
        'name': 'pH',
        'unit': '',
        'reverse_display': True,
        'levels': [
            (4.5, '1çº§', 'å¼ºé…¸æ€§'),
            (5.5, '2çº§', 'é…¸æ€§'),
            (6.5, '3çº§', 'å¼±é…¸æ€§'),
            (7.5, '4çº§', 'ä¸­æ€§'),
            (8.5, '5çº§', 'å¼±ç¢±æ€§'),
            (9.0, '6çº§', 'ç¢±æ€§'),
            (float('inf'), '7çº§', 'å¼ºç¢±æ€§')
        ]
    },

    # ========== è¡¨5ï¼šå…¶ä»–æŒ‡æ ‡åˆ†çº§æ ‡å‡†ï¼ˆè®¨è®ºç¨¿ï¼‰==========
    'æœ‰æ•ˆåœŸå±‚åšåº¦': {
        'name': 'æœ‰æ•ˆåœŸå±‚åšåº¦',
        'unit': 'cm',
        'reverse_display': True,
        'levels': [
            (10, '5çº§', 'â‰¤10'),
            (30, '4çº§', '10ï½30'),
            (50, '3çº§', '30ï½50'),
            (80, '2çº§', '50ï½80'),
            (float('inf'), '1çº§', '80ï½120')
        ]
    },
    'sand': {
        'name': 'æœºæ¢°ç»„æˆ-ç ‚ç²’',
        'unit': '%',
        'reverse_display': True,
        'levels': [
            (15, '5çº§', 'â‰¤15'),
            (25, '4çº§', '15ï½25'),
            (45, '3çº§', '25ï½45'),
            (65, '2çº§', '45ï½65'),
            (float('inf'), '1çº§', '65ï½100')
        ]
    },
    'silt': {
        'name': 'æœºæ¢°ç»„æˆ-ç²‰ç²’',
        'unit': '%',
        'reverse_display': True,
        'levels': [
            (15, '5çº§', 'â‰¤15'),
            (25, '4çº§', '15ï½25'),
            (45, '3çº§', '25ï½45'),
            (65, '2çº§', '45ï½65'),
            (float('inf'), '1çº§', '65ï½100')
        ]
    },
    'clay': {
        'name': 'æœºæ¢°ç»„æˆ-é»ç²’',
        'unit': '%',
        'reverse_display': True,
        'levels': [
            (15, '5çº§', 'â‰¤15'),
            (25, '4çº§', '15ï½25'),
            (45, '3çº§', '25ï½45'),
            (65, '2çº§', '45ï½65'),
            (float('inf'), '1çº§', '65ï½100')
        ]
    }
}

# åœŸå£¤è´¨åœ°åˆ†ç±»é…ç½®
SOIL_TEXTURE_MAPPING = {
    'ç ‚è´¨å£¤åœŸ': 'ç ‚å£¤ç±»',
    'ç²‰ç ‚è´¨å£¤åœŸ': 'è½»å£¤ç±»',
    'å£¤åœŸ': 'ä¸­å£¤ç±»',
    'ç ‚è´¨é»å£¤åœŸ': 'é»å£¤ç±»',
    'é»å£¤åœŸ': 'é»å£¤ç±»',
    'ç²‰ç ‚è´¨é»å£¤åœŸ': 'é»å£¤ç±»',
    'å£¤è´¨é»åœŸ': 'è½»é»ç±»',
    'ç²‰ç ‚è´¨é»åœŸ': 'è½»é»ç±»',
    'é»åœŸ': 'é»åœŸç±»'
}


# è¾…åŠ©å‡½æ•°ï¼šè·å–åœ°ç±»åˆ—å
def get_dlmc_column(df):
    """æ£€æµ‹å¹¶è¿”å›åœ°ç±»åˆ—åï¼ˆæ”¯æŒ'äºŒçº§åœ°ç±»'æˆ–'DLMC'ï¼‰"""
    if 'äºŒçº§åœ°ç±»' in df.columns:
        return 'äºŒçº§åœ°ç±»'
    elif 'DLMC' in df.columns:
        return 'DLMC'
    return None

# ç‰¹å®šå±æ€§çš„åœ°ç±»è¿‡æ»¤è§„åˆ™
SPECIFIC_FILTERS = {
    # è€•ä½œå±‚åšåº¦åªç»Ÿè®¡è€•åœ°ï¼ˆæ°´ç”°ã€æ°´æµ‡åœ°ã€æ—±åœ°ï¼‰
    'GZCHD': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°'])]
        if get_dlmc_column(df) else df
    ),
    
    # æœ‰æ•ˆç¡…åªç»Ÿè®¡æ°´ç”°
    'ASI': lambda df: (
        df[df[get_dlmc_column(df)].str.contains('æ°´ç”°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    
    # ä»¥ä¸‹å±æ€§åªç»Ÿè®¡è€•å›­åœ°ï¼ˆæ°´ç”°ã€æ°´æµ‡åœ°ã€æ—±åœ°ã€æœå›­ã€èŒ¶å›­ã€å›­åœ°ï¼‰
    'ECA': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'EMG': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'ENA': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'EK': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'SRXYZL': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'DDL': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'SK': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'AS1': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'AFE': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'AMN': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'ACU': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'AZN': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'AB': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'AMO': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
    'SWXDTJT7': lambda df: (
        df[df[get_dlmc_column(df)].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°', 'æœå›­', 'èŒ¶å›­']) | df[get_dlmc_column(df)].str.contains('å›­åœ°', case=False, na=False)]
        if get_dlmc_column(df) else df
    ),
}
ROMAN_LEVELS = ["â… ", "â…¡", "â…¢", "â…£", "â…¤", "â…¥", "â…¦"]


def format_small_value(value):
    """
    æ ¼å¼åŒ–å°æ•°å€¼:
    - å¤§äºç­‰äº 0.001: æ˜¾ç¤º3ä½å°æ•°
    - å°äº 0.001: æ˜¾ç¤ºåˆ°ç¬¬ä¸€ä½éé›¶æ•°å­—
    ä¾‹å¦‚: 0.000041 æ˜¾ç¤ºä¸º 0.00004
    """
    if pd.isna(value) or value == 0:
        return round(value, 3) if not pd.isna(value) else value
    
    abs_val = abs(value)
    
    # å¤§äºç­‰äº 0.001ï¼Œæ­£å¸¸æ˜¾ç¤º3ä½å°æ•°
    if abs_val >= 0.001:
        return round(value, 3)
    
    # å°äº 0.001ï¼Œæ˜¾ç¤ºåˆ°ç¬¬ä¸€ä½éé›¶æ•°å­—
    if abs_val == 0:
        return 0
    
    # è®¡ç®—éœ€è¦ä¿ç•™çš„å°æ•°ä½æ•°ï¼ˆåˆ°ç¬¬ä¸€ä½éé›¶æ•°å­—ï¼‰
    decimal_places = -int(math.floor(math.log10(abs_val)))
    return round(value, decimal_places)


def format_percentage(value):
    """
    æ ¼å¼åŒ–ç™¾åˆ†æ¯”æ•°å€¼:
    - å¦‚æœè¶…è¿‡100ï¼Œæ˜¾ç¤º100
    - å¦åˆ™æŒ‰ç…§ format_small_value é€»è¾‘å¤„ç†
    """
    if pd.isna(value):
        return value
    
    # å¦‚æœè¶…è¿‡100ï¼Œæ˜¾ç¤º100
    if value > 100:
        return 100
    
    return format_small_value(value)


def normalize_attr_column_name(col_name: str) -> str:
    """å°†åŸå§‹åˆ—åæ˜ å°„ä¸º SOIL_ATTR_CONFIG ä¸­çš„æ ‡å‡†é”®"""
    if pd.isna(col_name):
        return ""
    col_str = str(col_name).strip()

    # æ˜¾å¼åˆ«åæ˜ å°„ï¼ˆæ ¹æ®å¸¸è§æƒ…å†µæ‰©å±•ï¼‰
    alias_map = {
        'pH': 'ph',
        'PH': 'ph',
        'é…¸ç¢±åº¦': 'ph',
        'æœ‰æœºè´¨å«é‡': 'OM',
        'æœ‰æœºè´¨(g/kg)': 'OM',
        'å…¨æ°®å«é‡': 'TN',
        'æœ‰æ•ˆç£·(P)': 'AP',
        'é€Ÿæ•ˆé’¾(K)': 'AK',
        'é˜³ç¦»å­äº¤æ¢é‡(CEC)': 'CEC',
        'æ°´æº¶æ€§ç›': 'SRXYZL',
        'ç”µå¯¼ç‡(EC)': 'DDL',
        'æœ‰æ•ˆåœŸå±‚åšåº¦(cm)': 'æœ‰æ•ˆåœŸå±‚åšåº¦',
        'æœºæ¢°ç»„æˆ-ç ‚ç²’': 'sand',
        'æœºæ¢°ç»„æˆ-ç²‰ç²’': 'silt',
        'æœºæ¢°ç»„æˆ-é»ç²’': 'clay',
        # å¯ç»§ç»­æ·»åŠ ...
    }

    # å…ˆæŸ¥åˆ«å
    if col_str in alias_map:
        return alias_map[col_str]

    # å†ç›´æ¥åŒ¹é…ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    for key in SOIL_ATTR_CONFIG.keys():
        if col_str.lower() == key.lower():
            return key

    # å¦åˆ™è¿”å›åŸå­—ç¬¦ä¸²ï¼ˆå¤§æ¦‚ç‡ä¸åœ¨é…ç½®ä¸­ï¼‰
    return col_str


def detect_available_attributes(df_columns, config_keys):
    """
    æ£€æµ‹ DataFrame åˆ—ä¸­å“ªäº›å¯ä»¥åŒ¹é…åˆ° SOIL_ATTR_CONFIG
    è¿”å›ï¼š[(åŸå§‹åˆ—å, æ ‡å‡†é”®), ...]
    """
    available = []
    for col in df_columns:
        norm_key = normalize_attr_column_name(col)
        if norm_key in config_keys:
            available.append((col, norm_key))
    return available


def rename_attr_column_in_df(df, attr_key):
    """å°†æ•°æ®æ¡†ä¸­ä¸ attr_key ç›¸å…³çš„åˆ—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ç»Ÿä¸€é‡å‘½åä¸º attr_key"""
    target_col = None
    for col in df.columns:
        if col.strip().lower() == attr_key.lower():
            target_col = col
            break
    if target_col is None:
        config = SOIL_ATTR_CONFIG.get(attr_key, {})
        chinese_name = config.get('name', '')
        for col in df.columns:
            if col.strip() == chinese_name:
                target_col = col
                break
    if target_col is None:
        raise ValueError(f"æœªæ‰¾åˆ°åä¸º '{attr_key}' æˆ–å…¶ä¸­æ–‡åçš„åˆ—")
    df = df.rename(columns={target_col: attr_key})
    return df


def classify_by_config(value, attr_key):
    """æ ¹æ®é…ç½®å­—å…¸å¯¹å•ä¸ªå±æ€§å€¼è¿›è¡Œåˆ†çº§"""
    classified = classify_series_by_config(pd.Series([value]), attr_key)
    return classified.iloc[0]


def classify_series_by_config(values, attr_key):
    """å‘é‡åŒ–çš„å±æ€§åˆ†çº§ï¼Œå®ç°ç™¾ä¸‡çº§æ•°æ®å¤„ç†
    åˆ†çº§è§„åˆ™ï¼šå€¼ > å‰ä¸€ä¸ªé˜ˆå€¼ ä¸” <= å½“å‰é˜ˆå€¼
    """
    config = SOIL_ATTR_CONFIG.get(attr_key)
    if not config:
        return pd.Series([None] * len(values), index=values.index)

    numeric = pd.to_numeric(values, errors='coerce')
    notna_mask = pd.notna(numeric)
    nonzero_mask = (numeric != 0)
    valid_mask = np.logical_and(notna_mask, nonzero_mask)

    result = pd.Series([None] * len(values), index=values.index, dtype=object)
    if not np.any(valid_mask):
        return result

    thresholds = np.array([float(th[0]) for th in config['levels']], dtype=float)
    levels = [lvl for _, lvl, _ in config['levels']]

    # ä½¿ç”¨numpyå‡½æ•°å¤„ç†
    numeric_array = np.array(numeric)
    valid_mask_array = np.array(valid_mask)
    search_vals = numeric_array[valid_mask_array]
    search_vals = search_vals.astype(float)
    
    # ä½¿ç”¨ side='right' å®ç° <= çš„é€»è¾‘ï¼ˆå€¼ <= é˜ˆå€¼æ—¶å±äºè¯¥çº§åˆ«ï¼‰
    idx = np.searchsorted(thresholds, search_vals, side='right')
    idx = np.clip(idx, 0, len(levels) - 1)

    level_arr = [levels[i] for i in idx]
    result.loc[valid_mask] = level_arr
    return result


def map_land_use_series(series):
    """å‘é‡åŒ–åœŸåœ°åˆ©ç”¨åˆ†ç±»ï¼Œå‡å°‘é€è¡Œåˆ¤æ–­"""
    if series is None:
        return pd.Series(dtype=object)

    result = pd.Series(["å…¶ä»–"] * len(series), index=series.index, dtype=object)
    na_mask = series.isna()
    result.loc[na_mask] = None

    cleaned = series.astype(str).str.strip()
    farmland = cleaned.isin(["æ°´ç”°", "æ°´æµ‡åœ°", "æ—±åœ°"])
    result.loc[farmland] = "è€•åœ°"

    orchard = (~farmland) & (cleaned.isin(["æœå›­", "èŒ¶å›­"]) | cleaned.str.contains("å›­åœ°", na=False))
    result.loc[orchard] = "å›­åœ°"

    forest = (~farmland & ~orchard) & cleaned.str.contains("æ—åœ°", na=False)
    result.loc[forest] = "æ—åœ°"

    grass = (~farmland & ~orchard & ~forest) & cleaned.str.contains("è‰åœ°", na=False)
    result.loc[grass] = "è‰åœ°"

    return result


def get_level_range(attr_key):
    """è·å–å±æ€§å„çº§åˆ«çš„èŒƒå›´æè¿°åˆ—è¡¨ï¼ŒæŒ‰1çº§åˆ°5/7çº§é¡ºåº"""
    config = SOIL_ATTR_CONFIG.get(attr_key)
    if not config:
        return []
    if attr_key == 'ph':
        return [desc for _, _, desc in config['levels']]
    else:
        descs = [desc for _, _, desc in config['levels']]
        if config.get('reverse_display', False):
            return list(reversed(descs))
        else:
            return descs  # ä¸åè½¬


def get_grade_order(attr_key):
    """è·å–å±æ€§çº§åˆ«çš„æ’åºåˆ—è¡¨"""
    if attr_key == 'ph':
        return ['1çº§', '2çº§', '3çº§', '4çº§', '5çº§', '6çº§', '7çº§']
    else:
        return ['1çº§', '2çº§', '3çº§', '4çº§', '5çº§']


def get_level_value_ranges(attr_key):
    """è·å–å±æ€§å„çº§åˆ«çš„æ•°å€¼èŒƒå›´å­—ç¬¦ä¸²åˆ—è¡¨ï¼ŒæŒ‰1çº§åˆ°5/7çº§é¡ºåº
    åŒºé—´è¡¨ç¤ºè§„åˆ™ï¼šä¸­é—´çº§åˆ«ä½¿ç”¨ä¸­æ–‡æ³¢æµªçº¿~
    """
    config = SOIL_ATTR_CONFIG.get(attr_key)
    if not config:
        return []

    levels = config['levels']
    if attr_key == 'ph':
        ranges = []
        for i, (threshold, level, desc) in enumerate(levels):
            if i == 0:
                ranges.append(f"â‰¤{threshold}")
            elif i == len(levels) - 1:
                # pHçš„æœ€åä¸€çº§æ˜¯ >9
                prev = levels[i-1][0]
                ranges.append(f">{prev}")
            else:
                prev = levels[i-1][0]
                # ä¸­é—´çº§åˆ«ä½¿ç”¨ä¸­æ–‡æ³¢æµªçº¿
                ranges.append(f"{prev}ï½{threshold}")
        return ranges
    else:
        # æ„å»ºä»ä½åˆ°é«˜çš„æ•°å€¼åŒºé—´ï¼ˆæŒ‰ levels é¡ºåºï¼‰
        ranges = []
        for i, (threshold, level, desc) in enumerate(levels):
            if i == 0:
                # ç¬¬ä¸€ä¸ªçº§åˆ«ï¼šâ‰¤ threshold
                ranges.append(f"â‰¤{threshold}")
            elif i == len(levels) - 1:
                # æœ€åä¸€ä¸ªçº§åˆ«ï¼š> prev
                prev = levels[i-1][0]
                ranges.append(f">{prev}")
            else:
                # ä¸­é—´çº§åˆ«ä½¿ç”¨ä¸­æ–‡æ³¢æµªçº¿
                prev = levels[i-1][0]
                ranges.append(f"{prev}ï½{threshold}")

        # æ ¹æ® reverse_display å†³å®šæ˜¯å¦åè½¬
        if config.get('reverse_display', False):
            return list(reversed(ranges))
        else:
            return ranges


def generate_land_use_area_by_level_to_ws(ws, df_area, attr_key):
    """ç”Ÿæˆã€ŒåœŸåœ°åˆ©ç”¨ç±»å‹ Ã— å±æ€§åˆ†çº§é¢ç§¯ã€è¡¨"""
    config = SOIL_ATTR_CONFIG[attr_key]
    attr_name = config['name']
    unit = config['unit']
    ws.title = f"{attr_name}åˆ†çº§é¢ç§¯(åœŸåœ°åˆ©ç”¨)"

    grade_order = get_grade_order(attr_key)
    range_desc = get_level_value_ranges(attr_key)
    level_to_range = dict(zip(grade_order, range_desc))

    def get_land_class(dlmc):
        if pd.isna(dlmc):
            return None
        s = str(dlmc).strip()
        if s in ["æ°´ç”°", "æ°´æµ‡åœ°", "æ—±åœ°"]:
            return "è€•åœ°"
        elif s in ["æœå›­", "èŒ¶å›­"] or "å›­åœ°" in s:
            return "å›­åœ°"
        elif "æ—åœ°" in s:
            return "æ—åœ°"
        elif "è‰åœ°" in s:
            return "è‰åœ°"
        else:
            return "å…¶ä»–"

    df = df_area.copy()
    df[attr_key] = pd.to_numeric(df[attr_key], errors='coerce')
    if 'é¢ç§¯' not in df.columns:
        raise ValueError("åˆ¶å›¾æ•°æ®ç¼ºå°‘'é¢ç§¯'åˆ—")
    df['é¢ç§¯'] = pd.to_numeric(df['é¢ç§¯'], errors='coerce')
    df = df[
        df['é¢ç§¯'].notna() & (df['é¢ç§¯'] > 0) &
        df[attr_key].notna()
    ].copy()

    df['ç­‰çº§'] = classify_series_by_config(df[attr_key], attr_key)
    
    # æ£€æµ‹DLMCåˆ—å
    dlmc_col = 'äºŒçº§åœ°ç±»' if 'äºŒçº§åœ°ç±»' in df.columns else ('DLMC' if 'DLMC' in df.columns else None)
    land_use_source = df[dlmc_col] if dlmc_col else pd.Series([None] * len(df), index=df.index)
    df['åœŸåœ°åˆ©ç”¨'] = map_land_use_series(land_use_source)
    df = df.dropna(subset=['ç­‰çº§', 'åœŸåœ°åˆ©ç”¨'])

    land_types = ["è€•åœ°", "å›­åœ°", "æ—åœ°", "è‰åœ°", "å…¶ä»–"]
    if df.empty:
        grouped = pd.DataFrame(0.0, index=pd.Index(grade_order), columns=pd.Index(land_types))
    else:
        grouped = (
            df.groupby(['ç­‰çº§', 'åœŸåœ°åˆ©ç”¨'], observed=True)['é¢ç§¯']
              .sum()
              .unstack(fill_value=0.0)
        )
        grouped = grouped.reindex(index=grade_order, fill_value=0.0)
        grouped = grouped.reindex(columns=land_types, fill_value=0.0)

    total_by_level = grouped.sum(axis=1)
    grand_total = float(total_by_level.sum())

    # å†™å…¥è¡¨å¤´ï¼Œåˆå¹¶åˆ°å æ¯”åˆ—
    ws.merge_cells('A1:I1')
    ws['A1'] = f'{attr_name}åˆ†çº§é¢ç§¯ç»Ÿè®¡ï¼ˆæŒ‰åœŸåœ°åˆ©ç”¨ç±»å‹ï¼‰'
    ws['A1'].font = Font(bold=True, size=14)
    ws['A1'].alignment = Alignment(horizontal='center', vertical='center')

    # ç¬¬äºŒè¡Œåˆ—æ ‡é¢˜ï¼ˆä¸æ˜¾ç¤ºå•ä½ï¼‰
    headers = ['çº§åˆ«', 'åˆ†çº§æ ‡å‡†'] + land_types + ['æ€»é¢ç§¯/äº©', 'å æ¯”/%']
    
    for col_idx, header in enumerate(headers, start=1):
        cell = ws.cell(row=2, column=col_idx, value=header)
        cell.font = Font(bold=True)
        cell.alignment = Alignment(horizontal='center', vertical='center')

    for i, level in enumerate(grade_order):
        row_num = 3 + i
        roman = ROMAN_LEVELS[i] if i < len(ROMAN_LEVELS) else str(i + 1)
        ws.cell(row=row_num, column=1, value=roman)
        ws.cell(row=row_num, column=2, value=level_to_range.get(level, ''))
        for j, lt in enumerate(land_types):
            val = float(grouped.at[level, lt]) if (level in grouped.index and lt in grouped.columns) else 0.0
            ws.cell(row=row_num, column=3 + j, value=format_small_value(val))
        total_area_level = float(total_by_level.get(level, 0.0))
        ws.cell(row=row_num, column=8, value=format_small_value(total_area_level))
        pct = round(total_area_level / grand_total * 100, 2) if grand_total > 0 else 0.0
        ws.cell(row=row_num, column=9, value=format_percentage(pct))

    # åˆè®¡è¡Œ - åˆå¹¶å‰ä¸¤åˆ—
    ws.merge_cells(f'A{3 + len(grade_order)}:B{3 + len(grade_order)}')
    ws.cell(row=3 + len(grade_order), column=1, value="åˆè®¡")
    ws.cell(row=3 + len(grade_order), column=1).alignment = Alignment(horizontal='center', vertical='center')
    for j, lt in enumerate(land_types):
        col_sum = float(grouped[lt].sum()) if lt in grouped.columns else 0.0
        ws.cell(row=3 + len(grade_order), column=3 + j, value=format_small_value(col_sum))
    ws.cell(row=3 + len(grade_order), column=8, value=format_small_value(grand_total))
    ws.cell(row=3 + len(grade_order), column=9, value=100.0)

    thin = Side(border_style="thin")
    border = Border(top=thin, left=thin, right=thin, bottom=thin)
    max_row = 3 + len(grade_order)
    for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=9):
        for cell in row:
            cell.border = border
            cell.alignment = Alignment(horizontal='center', vertical='center')
    for col in range(1, 10):
        ws.column_dimensions[get_column_letter(col)].width = 12


def generate_town_area_by_level_to_ws(ws, df_area, attr_key):
    """ç”Ÿæˆã€Œä¹¡é•‡ Ã— å±æ€§åˆ†çº§é¢ç§¯ã€è¡¨"""
    # åªç»Ÿè®¡è€•åœ°ï¼ˆæ°´ç”°ã€æ°´æµ‡åœ°ã€æ—±åœ°ï¼‰
    dlmc_col = 'äºŒçº§åœ°ç±»' if 'äºŒçº§åœ°ç±»' in df_area.columns else ('DLMC' if 'DLMC' in df_area.columns else None)
    if dlmc_col:
        df_area = df_area[df_area[dlmc_col].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°'])]
        
        # ç‰¹æ®Šå¤„ç†ï¼šæœ‰æ•ˆç¡…(ASI)åªç»Ÿè®¡æ°´ç”°
        if attr_key == 'ASI':
            df_area = df_area[df_area[dlmc_col].str.contains('æ°´ç”°', case=False, na=False)]
    
    config = SOIL_ATTR_CONFIG[attr_key]
    attr_name = config['name']
    unit = config['unit']
    ws.title = f"{attr_name}åˆ†çº§é¢ç§¯(ä¹¡é•‡)"

    grade_order = get_grade_order(attr_key)
    range_desc = get_level_value_ranges(attr_key)
    level_to_range = dict(zip(grade_order, range_desc))

    df = df_area.copy()
    df[attr_key] = pd.to_numeric(df[attr_key], errors='coerce')
    if 'é¢ç§¯' not in df.columns:
        raise ValueError("åˆ¶å›¾æ•°æ®ç¼ºå°‘'é¢ç§¯'åˆ—")
    df['é¢ç§¯'] = pd.to_numeric(df['é¢ç§¯'], errors='coerce')
    df = df[
        df['é¢ç§¯'].notna() & (df['é¢ç§¯'] > 0) &
        df[attr_key].notna()
    ].copy()

    df['ç­‰çº§'] = classify_series_by_config(df[attr_key], attr_key)
    df = df.dropna(subset=['ç­‰çº§', 'è¡Œæ”¿åŒºåç§°']).copy()
    df['è¡Œæ”¿åŒºåç§°'] = df['è¡Œæ”¿åŒºåç§°'].astype(str).str.strip()

    if df.empty:
        towns = ["æ— ä¹¡é•‡æ•°æ®"]
        grouped = pd.DataFrame(0.0, index=pd.Index(grade_order), columns=pd.Index(towns))
    else:
        # æŒ‰æ‹¼éŸ³æ’åºä¹¡é•‡åç§°
        import locale
        try:
            locale.setlocale(locale.LC_COLLATE, 'zh_CN.UTF-8')
            towns = sorted(df['è¡Œæ”¿åŒºåç§°'].unique(), key=locale.strxfrm)
        except:
            # å¦‚æœlocaleè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ’åº
            towns = sorted(df['è¡Œæ”¿åŒºåç§°'].unique())
        
        grouped = (
            df.groupby(['ç­‰çº§', 'è¡Œæ”¿åŒºåç§°'], observed=True)['é¢ç§¯']
              .sum()
              .unstack(fill_value=0.0)
        )
        grouped = grouped.reindex(index=grade_order, fill_value=0.0)
        grouped = grouped.reindex(columns=pd.Index(towns), fill_value=0.0)

    total_by_level = grouped.sum(axis=1)
    grand_total = float(total_by_level.sum())

    # åˆå¹¶æ ‡é¢˜åˆ°å æ¯”åˆ—
    ws.merge_cells(start_row=1, start_column=1, end_row=1, end_column=len(towns)+4)
    ws['A1'] = f'{attr_name}åˆ†çº§é¢ç§¯ç»Ÿè®¡ï¼ˆåˆ†ä¹¡é•‡ï¼‰'
    ws['A1'].font = Font(bold=True, size=14)
    ws['A1'].alignment = Alignment(horizontal='center', vertical='center')

    ws.cell(row=2, column=1, value="çº§åˆ«")
    ws.cell(row=2, column=2, value="åˆ†çº§æ ‡å‡†")  # ä¸æ˜¾ç¤ºå•ä½
    for i, town in enumerate(towns):
        ws.cell(row=2, column=3 + i, value=town)
    ws.cell(row=2, column=3 + len(towns), value="æ€»é¢ç§¯/äº©")
    ws.cell(row=2, column=3 + len(towns) + 1, value="å æ¯”/%")

    for col in range(1, 3 + len(towns) + 2):
        ws.cell(row=2, column=col).font = Font(bold=True)
        ws.cell(row=2, column=col).alignment = Alignment(horizontal='center', vertical='center')

    for i, level in enumerate(grade_order):
        row_num = 3 + i
        roman = ROMAN_LEVELS[i] if i < len(ROMAN_LEVELS) else str(i + 1)
        ws.cell(row=row_num, column=1, value=roman)
        ws.cell(row=row_num, column=2, value=level_to_range.get(level, ''))
        for j, town in enumerate(towns):
            val = float(grouped.at[level, town]) if (level in grouped.index and town in grouped.columns) else 0.0
            ws.cell(row=row_num, column=3 + j, value=format_small_value(val))
        total_area_level = float(total_by_level.get(level, 0.0))
        ws.cell(row=row_num, column=3 + len(towns), value=format_small_value(total_area_level))
        pct = round(total_area_level / grand_total * 100, 2) if grand_total > 0 else 0.0
        ws.cell(row=row_num, column=3 + len(towns) + 1, value=format_percentage(pct))

    # åˆè®¡è¡Œ - åˆå¹¶å‰ä¸¤åˆ—
    ws.merge_cells(f'A{3 + len(grade_order)}:B{3 + len(grade_order)}')
    ws.cell(row=3 + len(grade_order), column=1, value="åˆè®¡")
    ws.cell(row=3 + len(grade_order), column=1).alignment = Alignment(horizontal='center', vertical='center')
    for j, town in enumerate(towns):
        col_sum = float(grouped[town].sum()) if town in grouped.columns else 0.0
        ws.cell(row=3 + len(grade_order), column=3 + j, value=format_small_value(col_sum))
    ws.cell(row=3 + len(grade_order), column=3 + len(towns), value=format_small_value(grand_total))
    ws.cell(row=3 + len(grade_order), column=3 + len(towns) + 1, value=100.0)

    thin = Side(border_style="thin")
    border = Border(top=thin, left=thin, right=thin, bottom=thin)
    max_row = 3 + len(grade_order)
    max_col = 3 + len(towns) + 1
    for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col):
        for cell in row:
            cell.border = border
            cell.alignment = Alignment(horizontal='center', vertical='center')
    for col in range(1, max_col + 1):
        ws.column_dimensions[get_column_letter(col)].width = 12


def generate_soil_texture_by_land_use_to_ws(ws, df_area):
    """ç”ŸæˆåœŸå£¤è´¨åœ°æŒ‰åœŸåœ°åˆ©ç”¨ç±»å‹ç»Ÿè®¡è¡¨"""
    ws.title = "åœŸå£¤è´¨åœ°é¢ç§¯(åœŸåœ°åˆ©ç”¨)"
    
    df = df_area.copy()
    
    # æ£€æŸ¥TRZDåˆ—æ˜¯å¦å­˜åœ¨
    if 'TRZD' not in df.columns:
        ws.merge_cells('A1:D1')
        ws['A1'] = 'åœŸå£¤è´¨åœ°é¢ç§¯ç»Ÿè®¡ï¼ˆç¼ºå°‘TRZDåˆ—ï¼‰'
        ws['A1'].font = Font(bold=True, size=14)
        ws['A1'].alignment = Alignment(horizontal='center', vertical='center')
        return
    
    if 'é¢ç§¯' not in df.columns:
        raise ValueError("åˆ¶å›¾æ•°æ®ç¼ºå°‘'é¢ç§¯'åˆ—")
    
    df['é¢ç§¯'] = pd.to_numeric(df['é¢ç§¯'], errors='coerce')
    df = df[df['é¢ç§¯'].notna() & (df['é¢ç§¯'] != 0)].copy()
    
    # æ˜ å°„åˆ°å¤§ç±»
    df['TRZD'] = df['TRZD'].astype(str).str.strip()
    df['è´¨åœ°å¤§ç±»'] = df['TRZD'].map(SOIL_TEXTURE_MAPPING)
    
    # è·å–åœŸåœ°åˆ©ç”¨ç±»å‹
    def get_land_class(dlmc):
        if pd.isna(dlmc):
            return None
        s = str(dlmc).strip()
        if s in ["æ°´ç”°", "æ°´æµ‡åœ°", "æ—±åœ°"]:
            return "è€•åœ°"
        elif s in ["æœå›­", "èŒ¶å›­"] or "å›­åœ°" in s:
            return "å›­åœ°"
        elif "æ—åœ°" in s:
            return "æ—åœ°"
        elif "è‰åœ°" in s:
            return "è‰åœ°"
        else:
            return "å…¶ä»–"
    
    # æ£€æµ‹DLMCåˆ—å
    dlmc_col = 'äºŒçº§åœ°ç±»' if 'äºŒçº§åœ°ç±»' in df.columns else ('DLMC' if 'DLMC' in df.columns else None)
    land_use_source = df[dlmc_col] if dlmc_col else pd.Series([None] * len(df), index=df.index)
    df['åœŸåœ°åˆ©ç”¨'] = land_use_source.apply(get_land_class)
    df = df.dropna(subset=['è´¨åœ°å¤§ç±»', 'åœŸåœ°åˆ©ç”¨'])
    
    # å®šä¹‰é¡ºåº
    texture_order = ['ç ‚å£¤ç±»', 'è½»å£¤ç±»', 'ä¸­å£¤ç±»', 'é»å£¤ç±»', 'è½»é»ç±»', 'é»åœŸç±»']
    land_types = ["è€•åœ°", "å›­åœ°", "æ—åœ°", "è‰åœ°", "å…¶ä»–"]
    
    # å®šä¹‰æ¯ä¸ªå¤§ç±»åŒ…å«çš„å…·ä½“ç±»å‹
    texture_details = {
        'ç ‚å£¤ç±»': ['ç ‚è´¨å£¤åœŸ'],
        'è½»å£¤ç±»': ['ç²‰ç ‚è´¨å£¤åœŸ'],
        'ä¸­å£¤ç±»': ['å£¤åœŸ'],
        'é»å£¤ç±»': ['ç ‚è´¨é»å£¤åœŸ', 'é»å£¤åœŸ', 'ç²‰ç ‚è´¨é»å£¤åœŸ'],
        'è½»é»ç±»': ['å£¤è´¨é»åœŸ', 'ç²‰ç ‚è´¨é»åœŸ'],
        'é»åœŸç±»': ['é»åœŸ']
    }
    
    # æŒ‰å…·ä½“ç±»å‹å’ŒåœŸåœ°åˆ©ç”¨ç»Ÿè®¡
    grouped_detail = df.groupby(['TRZD', 'åœŸåœ°åˆ©ç”¨'], observed=True)['é¢ç§¯'].sum().unstack(fill_value=0.0)
    grouped_detail = grouped_detail.reindex(columns=land_types, fill_value=0.0)
    
    # è®¡ç®—æ€»è®¡
    grand_total = df['é¢ç§¯'].sum()
    
    # å†™å…¥è¡¨å¤´ï¼Œåˆå¹¶åˆ°å æ¯”åˆ—
    ws.merge_cells('A1:I1')
    ws['A1'] = 'åœŸå£¤è´¨åœ°é¢ç§¯ç»Ÿè®¡ï¼ˆæŒ‰åœŸåœ°åˆ©ç”¨ç±»å‹ï¼‰'
    ws['A1'].font = Font(bold=True, size=14)
    ws['A1'].alignment = Alignment(horizontal='center', vertical='center')
    
    # åˆ—æ ‡é¢˜
    ws['A2'] = 'åœŸå£¤è´¨åœ°çº§åˆ«'
    ws['B2'] = 'åˆ†çº§æ ‡å‡†'
    ws['C2'] = 'è€•åœ°'
    ws['D2'] = 'å›­åœ°'
    ws['E2'] = 'æ—åœ°'
    ws['F2'] = 'è‰åœ°'
    ws['G2'] = 'å…¶ä»–'
    ws['H2'] = 'æ€»é¢ç§¯/äº©'
    ws['I2'] = 'å æ¯”/%'
    
    for col in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']:
        ws[col + '2'].font = Font(bold=True)
        ws[col + '2'].alignment = Alignment(horizontal='center', vertical='center')
    
    current_row = 3
    
    # æŒ‰å¤§ç±»é¡ºåºå†™å…¥æ•°æ®
    for texture_class in texture_order:
        detail_types = texture_details[texture_class]
        start_row = current_row
        
        # å†™å…¥æ¯ä¸ªå…·ä½“ç±»å‹
        for detail_type in detail_types:
            if detail_type not in grouped_detail.index:
                continue
            
            # å…·ä½“ç±»å‹åç§°
            ws.cell(row=current_row, column=2, value=detail_type)
            
            # å„åœŸåœ°åˆ©ç”¨ç±»å‹é¢ç§¯
            for j, lt in enumerate(land_types):
                val = float(grouped_detail.at[detail_type, lt]) if lt in grouped_detail.columns else 0.0
                ws.cell(row=current_row, column=3 + j, value=format_small_value(val))
            
            # è®¡ç®—è¯¥å…·ä½“ç±»å‹çš„æ€»é¢ç§¯å’Œå æ¯”
            row_total = grouped_detail.loc[detail_type].sum()
            ws.cell(row=current_row, column=8, value=format_small_value(row_total))
            pct = round(row_total / grand_total * 100, 2) if grand_total > 0 else 0.0
            ws.cell(row=current_row, column=9, value=format_percentage(pct))
            
            current_row += 1
        
        # åˆå¹¶å¤§ç±»å•å…ƒæ ¼
        end_row = current_row - 1
        if end_row >= start_row:
            if end_row > start_row:
                ws.merge_cells(f'A{start_row}:A{end_row}')
            ws.cell(row=start_row, column=1, value=texture_class)
            ws.cell(row=start_row, column=1).alignment = Alignment(horizontal='center', vertical='center')
    
    # è®¾ç½®è¾¹æ¡†å’Œå¯¹é½
    thin = Side(border_style="thin")
    border = Border(top=thin, left=thin, right=thin, bottom=thin)
    max_row = current_row - 1
    for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=9):
        for cell in row:
            cell.border = border
            cell.alignment = Alignment(horizontal='center', vertical='center')
    for col in range(1, 10):
        ws.column_dimensions[get_column_letter(col)].width = 12


def generate_soil_texture_by_town_to_ws(ws, df_area):
    """ç”ŸæˆåœŸå£¤è´¨åœ°æŒ‰ä¹¡é•‡ç»Ÿè®¡è¡¨"""
    ws.title = "åœŸå£¤è´¨åœ°é¢ç§¯(ä¹¡é•‡)"
    
    # åªç»Ÿè®¡è€•åœ°
    dlmc_col = 'äºŒçº§åœ°ç±»' if 'äºŒçº§åœ°ç±»' in df_area.columns else ('DLMC' if 'DLMC' in df_area.columns else None)
    if dlmc_col:
        df_area = df_area[df_area[dlmc_col].isin(['æ°´ç”°', 'æ°´æµ‡åœ°', 'æ—±åœ°'])]
    
    df = df_area.copy()
    
    # æ£€æŸ¥TRZDåˆ—æ˜¯å¦å­˜åœ¨
    if 'TRZD' not in df.columns:
        ws.merge_cells('A1:D1')
        ws['A1'] = 'åœŸå£¤è´¨åœ°é¢ç§¯ç»Ÿè®¡ï¼ˆç¼ºå°‘TRZDåˆ—ï¼‰'
        ws['A1'].font = Font(bold=True, size=14)
        ws['A1'].alignment = Alignment(horizontal='center', vertical='center')
        return
    
    if 'é¢ç§¯' not in df.columns:
        raise ValueError("åˆ¶å›¾æ•°æ®ç¼ºå°‘'é¢ç§¯'åˆ—")
    
    df['é¢ç§¯'] = pd.to_numeric(df['é¢ç§¯'], errors='coerce')
    df = df[df['é¢ç§¯'].notna() & (df['é¢ç§¯'] != 0)].copy()
    
    # æ˜ å°„åˆ°å¤§ç±»
    df['TRZD'] = df['TRZD'].astype(str).str.strip()
    df['è´¨åœ°å¤§ç±»'] = df['TRZD'].map(SOIL_TEXTURE_MAPPING)
    df = df.dropna(subset=['è´¨åœ°å¤§ç±»', 'è¡Œæ”¿åŒºåç§°']).copy()
    df['è¡Œæ”¿åŒºåç§°'] = df['è¡Œæ”¿åŒºåç§°'].astype(str).str.strip()
    
    # å®šä¹‰é¡ºåº
    texture_order = ['ç ‚å£¤ç±»', 'è½»å£¤ç±»', 'ä¸­å£¤ç±»', 'é»å£¤ç±»', 'è½»é»ç±»', 'é»åœŸç±»']
    
    # å®šä¹‰æ¯ä¸ªå¤§ç±»åŒ…å«çš„å…·ä½“ç±»å‹
    texture_details = {
        'ç ‚å£¤ç±»': ['ç ‚è´¨å£¤åœŸ'],
        'è½»å£¤ç±»': ['ç²‰ç ‚è´¨å£¤åœŸ'],
        'ä¸­å£¤ç±»': ['å£¤åœŸ'],
        'é»å£¤ç±»': ['ç ‚è´¨é»å£¤åœŸ', 'é»å£¤åœŸ', 'ç²‰ç ‚è´¨é»å£¤åœŸ'],
        'è½»é»ç±»': ['å£¤è´¨é»åœŸ', 'ç²‰ç ‚è´¨é»åœŸ'],
        'é»åœŸç±»': ['é»åœŸ']
    }
    
    if df.empty:
        towns = ["æ— ä¹¡é•‡æ•°æ®"]
    else:
        # æŒ‰æ‹¼éŸ³æ’åºä¹¡é•‡åç§°
        import locale
        try:
            locale.setlocale(locale.LC_COLLATE, 'zh_CN.UTF-8')
            towns = sorted(df['è¡Œæ”¿åŒºåç§°'].unique(), key=locale.strxfrm)
        except:
            # å¦‚æœlocaleè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ’åº
            towns = sorted(df['è¡Œæ”¿åŒºåç§°'].unique())
    
    # æŒ‰å…·ä½“ç±»å‹å’Œä¹¡é•‡ç»Ÿè®¡
    grouped_detail = df.groupby(['TRZD', 'è¡Œæ”¿åŒºåç§°'], observed=True)['é¢ç§¯'].sum().unstack(fill_value=0.0)
    grouped_detail = grouped_detail.reindex(columns=towns, fill_value=0.0)
    
    # è®¡ç®—æ€»è®¡
    grand_total = df['é¢ç§¯'].sum()
    
    # å†™å…¥è¡¨å¤´ï¼Œåˆå¹¶åˆ°å æ¯”åˆ—
    ws.merge_cells(start_row=1, start_column=1, end_row=1, end_column=len(towns)+4)
    ws['A1'] = 'åœŸå£¤è´¨åœ°é¢ç§¯ç»Ÿè®¡ï¼ˆåˆ†ä¹¡é•‡ï¼‰'
    ws['A1'].font = Font(bold=True, size=14)
    ws['A1'].alignment = Alignment(horizontal='center', vertical='center')
    
    # åˆ—æ ‡é¢˜
    ws.cell(row=2, column=1, value="åœŸå£¤è´¨åœ°çº§åˆ«")
    ws.cell(row=2, column=2, value="åˆ†çº§æ ‡å‡†")
    for i, town in enumerate(towns):
        ws.cell(row=2, column=3 + i, value=town)
    ws.cell(row=2, column=3 + len(towns), value="æ€»é¢ç§¯/äº©")
    ws.cell(row=2, column=3 + len(towns) + 1, value="å æ¯”/%")
    
    for col in range(1, 3 + len(towns) + 2):
        ws.cell(row=2, column=col).font = Font(bold=True)
        ws.cell(row=2, column=col).alignment = Alignment(horizontal='center', vertical='center')
    
    current_row = 3
    
    # æŒ‰å¤§ç±»é¡ºåºå†™å…¥æ•°æ®
    for texture_class in texture_order:
        detail_types = texture_details[texture_class]
        start_row = current_row
        
        # å†™å…¥æ¯ä¸ªå…·ä½“ç±»å‹
        for detail_type in detail_types:
            if detail_type not in grouped_detail.index:
                continue
            
            # å…·ä½“ç±»å‹åç§°
            ws.cell(row=current_row, column=2, value=detail_type)
            
            # å„ä¹¡é•‡é¢ç§¯
            for j, town in enumerate(towns):
                val = float(grouped_detail.at[detail_type, town]) if town in grouped_detail.columns else 0.0
                ws.cell(row=current_row, column=3 + j, value=format_small_value(val))
            
            # è®¡ç®—è¯¥å…·ä½“ç±»å‹çš„æ€»é¢ç§¯å’Œå æ¯”
            row_total = grouped_detail.loc[detail_type].sum()
            ws.cell(row=current_row, column=3 + len(towns), value=format_small_value(row_total))
            pct = round(row_total / grand_total * 100, 2) if grand_total > 0 else 0.0
            ws.cell(row=current_row, column=3 + len(towns) + 1, value=format_percentage(pct))
            
            current_row += 1
        
        # åˆå¹¶å¤§ç±»å•å…ƒæ ¼
        end_row = current_row - 1
        if end_row >= start_row:
            if end_row > start_row:
                ws.merge_cells(f'A{start_row}:A{end_row}')
            ws.cell(row=start_row, column=1, value=texture_class)
            ws.cell(row=start_row, column=1).alignment = Alignment(horizontal='center', vertical='center')
    
    # è®¾ç½®è¾¹æ¡†å’Œå¯¹é½
    thin = Side(border_style="thin")
    border = Border(top=thin, left=thin, right=thin, bottom=thin)
    max_row = current_row - 1
    max_col = 3 + len(towns) + 1
    for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col):
        for cell in row:
            cell.border = border
            cell.alignment = Alignment(horizontal='center', vertical='center')
    for col in range(1, max_col + 1):
        ws.column_dimensions[get_column_letter(col)].width = 12


def read_csv_safe(filepath):
    with open(filepath, 'rb') as f:
        raw = f.read(10000)
        enc = chardet.detect(raw)['encoding']
        if enc is None:
            enc = 'utf-8'
        if enc.lower() in ['gb2312', 'gbk', 'cp936']:
            enc = 'gbk'
    try:
        return pd.read_csv(filepath, encoding=enc)
    except Exception as e:
        raise ValueError(f"æ— æ³•è¯»å– {filepath}ï¼ˆç¼–ç : {enc}ï¼‰: {e}")


def process_files(area_paths, output_path, progress_callback=None):
    try:
        if progress_callback:
            progress_callback(0, "æ­£åœ¨è¯»å–åˆ¶å›¾æ•°æ®...")
        
        # è¯»å–å¤šä¸ªåˆ¶å›¾ç»Ÿè®¡æ–‡ä»¶å¹¶åˆå¹¶
        df_area_list = []
        for idx, area_path in enumerate(area_paths):
            if progress_callback:
                progress_callback(5 + idx * 10, f"æ­£åœ¨è¯»å–åˆ¶å›¾æ•°æ® {idx+1}/{len(area_paths)}...")
            df_area = read_csv_safe(area_path)
            df_area_list.append(df_area)

        # åˆå¹¶æ‰€æœ‰åˆ¶å›¾ç»Ÿè®¡æ•°æ®
        if progress_callback:
            progress_callback(20, "æ­£åœ¨åˆå¹¶åˆ¶å›¾æ•°æ®...")
        df_area_raw = pd.concat(df_area_list, ignore_index=True)

        # æ£€æµ‹æ‰€æœ‰å¯åˆ†æçš„å±æ€§ï¼ˆåŸå§‹åˆ— â†’ æ ‡å‡†é”®ï¼‰
        if progress_callback:
            progress_callback(25, "æ­£åœ¨æ£€æµ‹å±æ€§...")
        available_attrs = detect_available_attributes(df_area_raw.columns, set(SOIL_ATTR_CONFIG.keys()))
        if not available_attrs:
            return False, "æœªåœ¨åˆ¶å›¾ç»Ÿè®¡æ•°æ®ä¸­æ‰¾åˆ°ä»»ä½•æ”¯æŒçš„åœŸå£¤å±æ€§åˆ—ï¼"

        wb = Workbook()
        # åˆ é™¤é»˜è®¤çš„ Sheet
        if wb.active is not None:
            wb.remove(wb.active)

        processed_any = False
        total_attrs = len(available_attrs)

        for attr_idx, (orig_col, attr_key) in enumerate(available_attrs):
            try:
                if progress_callback:
                    progress = 30 + int((attr_idx / total_attrs) * 60)
                    progress_callback(progress, f"æ­£åœ¨å¤„ç†å±æ€§: {SOIL_ATTR_CONFIG[attr_key]['name']} ({attr_idx+1}/{total_attrs})...")
                
                # å°è¯•æ ‡å‡†åŒ–åˆ—åï¼ˆç¡®ä¿ä¸¤è¡¨éƒ½æœ‰è¯¥åˆ—ï¼‰
                df_temp = df_area_raw.copy()
                df_area = rename_attr_column_in_df(df_temp, attr_key)
          
                if attr_key in SPECIFIC_FILTERS:
                    df_area = SPECIFIC_FILTERS[attr_key](df_area)

                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°å€¼ï¼ˆæ’é™¤0å€¼ï¼‰
                area_vals = pd.to_numeric(df_area[attr_key], errors='coerce')
                # ä½¿ç”¨numpyæ•°ç»„é¿å…ç±»å‹é”™è¯¯
                area_vals_np = np.array(area_vals)
                area_vals_np = area_vals_np[area_vals_np != 0]
                area_vals = pd.Series(area_vals_np).dropna()

                if len(area_vals) == 0:
                    continue

                # ç”Ÿæˆä¸¤ä¸ª sheetï¼ˆä»…ç”Ÿæˆæ‰€éœ€çš„ä¸¤ä¸ªè¡¨ï¼‰
                ws1 = wb.create_sheet(title=f"{SOIL_ATTR_CONFIG[attr_key]['name']}åˆ†çº§é¢ç§¯(åœŸåœ°åˆ©ç”¨)")
                ws2 = wb.create_sheet(title=f"{SOIL_ATTR_CONFIG[attr_key]['name']}åˆ†çº§é¢ç§¯(ä¹¡é•‡)")

                generate_land_use_area_by_level_to_ws(ws1, df_area, attr_key)
                generate_town_area_by_level_to_ws(ws2, df_area, attr_key)

                processed_any = True

            except Exception as e:
                continue
        
        # ç”ŸæˆåœŸå£¤è´¨åœ°ç»Ÿè®¡è¡¨ï¼ˆç”Ÿæˆ2å¼ è¡¨ï¼‰
        try:
            if progress_callback:
                progress_callback(95, "æ­£åœ¨ç”ŸæˆåœŸå£¤è´¨åœ°ç»Ÿè®¡è¡¨...")
            
            # æŒ‰åœŸåœ°åˆ©ç”¨ç±»å‹ç»Ÿè®¡
            ws_texture_land = wb.create_sheet(title="åœŸå£¤è´¨åœ°é¢ç§¯(åœŸåœ°åˆ©ç”¨)")
            generate_soil_texture_by_land_use_to_ws(ws_texture_land, df_area_raw)
            
            # æŒ‰ä¹¡é•‡ç»Ÿè®¡
            ws_texture_town = wb.create_sheet(title="åœŸå£¤è´¨åœ°é¢ç§¯(ä¹¡é•‡)")
            generate_soil_texture_by_town_to_ws(ws_texture_town, df_area_raw)
        except Exception as e:
            pass

        if not processed_any:
            return False, "æ‰€æœ‰æ£€æµ‹åˆ°çš„å±æ€§å‡æ— æ³•å¤„ç†ï¼ˆç¼ºå°‘æ•°æ®æˆ–æ ¼å¼é”™è¯¯ï¼‰ã€‚"

        if progress_callback:
            progress_callback(98, "æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
        wb.save(output_path)
        
        if progress_callback:
            progress_callback(100, "å®Œæˆï¼")
        return True, None

    except Exception as e:
        import traceback
        traceback.print_exc()
        return False, str(e)


class App:
    def __init__(self, root):
        self.root = root
        self.root.title("åœŸå£¤å±æ€§åˆ†çº§ç»Ÿè®¡å·¥å…·")
        self.root.geometry("580x400")
        self.area_files = []

        tk.Label(root, text="åœŸå£¤å±æ€§ä¸Šå›¾ç»Ÿè®¡å·¥å…·ï¼ˆæ”¯æŒå¤šåˆ¶å›¾ç»Ÿè®¡æ–‡ä»¶ï¼‰", font=("Arial", 12, "bold")).pack(pady=8)
        tk.Label(root, text="â€¢ æ”¯æŒæ‰€æœ‰é…ç½®ä¸­çš„åœŸå£¤å±æ€§\nâ€¢ æ–‡ä»¶åè‡ªåŠ¨å¸¦æ—¶é—´æˆ³", fg="gray").pack()

        tk.Button(root, text="ğŸ“ é€‰æ‹©ã€åˆ¶å›¾ç»Ÿè®¡.csvã€‘æ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰", command=self.select_area).pack(pady=6)
        self.label_area = tk.Label(root, text="æœªé€‰æ‹©", fg="gray")
        self.label_area.pack()

        tk.Button(root, text="âœ… ç”Ÿæˆç»Ÿè®¡è¡¨", command=self.run_process, bg="#4CAF50", fg="white",
                  font=("Arial", 12)).pack(pady=15)

        # æ·»åŠ ä¸€ä¸ªæ–‡æœ¬æ¡†æ˜¾ç¤ºå·²é€‰æ‹©çš„åˆ¶å›¾ç»Ÿè®¡æ–‡ä»¶
        self.area_listbox_frame = tk.Frame(root)
        self.area_listbox_frame.pack(pady=5, fill=tk.X, padx=20)
        self.area_listbox_label = tk.Label(self.area_listbox_frame, text="å·²é€‰æ‹©çš„åˆ¶å›¾ç»Ÿè®¡æ–‡ä»¶ï¼š")
        self.area_listbox_label.pack(anchor=tk.W)
        self.area_listbox = tk.Listbox(self.area_listbox_frame, height=3)
        self.area_listbox.pack(fill=tk.X, pady=2)
        self.scrollbar = tk.Scrollbar(self.area_listbox_frame, orient=tk.VERTICAL, command=self.area_listbox.yview)
        self.area_listbox.config(yscrollcommand=self.scrollbar.set)
        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        # æ·»åŠ è¿›åº¦æ¡
        self.progress_frame = tk.Frame(root)
        self.progress_frame.pack(pady=10, fill=tk.X, padx=20)
        self.progress_label = tk.Label(self.progress_frame, text="", fg="blue")
        self.progress_label.pack()
        self.progress_bar = ttk.Progressbar(self.progress_frame, length=500, mode='determinate')
        self.progress_bar.pack(pady=5)

    def select_area(self):
        files = filedialog.askopenfilenames(filetypes=[("CSV files", "*.csv")])
        if files:
            self.area_files = list(files)
            self.label_area.config(text=f"å·²é€‰æ‹© {len(self.area_files)} ä¸ªæ–‡ä»¶", fg="black")
            # æ¸…ç©ºåˆ—è¡¨æ¡†
            self.area_listbox.delete(0, tk.END)
            # æ·»åŠ æ–‡ä»¶ååˆ°åˆ—è¡¨æ¡†
            for file_path in self.area_files:
                self.area_listbox.insert(tk.END, file_path.split("/")[-1])

    def update_progress(self, value, message):
        """æ›´æ–°è¿›åº¦æ¡å’ŒçŠ¶æ€æ¶ˆæ¯"""
        self.progress_bar['value'] = value
        self.progress_label.config(text=message)
        self.root.update_idletasks()

    def run_process(self):
        if not self.area_files:
            messagebox.showwarning("âš ï¸ æç¤º", "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ¶å›¾ç»Ÿè®¡CSVæ–‡ä»¶ï¼")
            return

        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        output = f"åœŸå£¤å±æ€§ä¸Šå›¾ç»Ÿè®¡_{timestamp}.xlsx"

        # é‡ç½®è¿›åº¦æ¡
        self.progress_bar['value'] = 0
        self.progress_label.config(text="å‡†å¤‡å¼€å§‹...")
        
        success, msg = process_files(self.area_files, output, self.update_progress)
        if success:
            messagebox.showinfo("ğŸ‰ æˆåŠŸ", f"æ–‡ä»¶å·²ç”Ÿæˆï¼š\n{output}")
            # é‡ç½®è¿›åº¦æ¡
            self.progress_bar['value'] = 0
            self.progress_label.config(text="")
        else:
            messagebox.showerror("âŒ é”™è¯¯", f"å¤„ç†å¤±è´¥ï¼š\n{msg}")
            # é‡ç½®è¿›åº¦æ¡
            self.progress_bar['value'] = 0
            self.progress_label.config(text="")


if __name__ == "__main__":
    root = tk.Tk()
    app = App(root)
    root.mainloop()
